from typing import Callable, List, Optional, Tuple, Union

import pandas as pd
from sklearn.base import BaseEstimator

from ..all_types import TransformationsOverTime
from ..models.base import Model
from ..splitters import Split, Splitter
from ..transformations.base import (
    BlocksOrWrappable,
    Composite,
    DeployableTransformations,
    Transformation,
    Transformations,
)
from ..utils.list import wrap_in_list
from .backend.ray import train_transformations as _train_transformations_ray
from .backend.sequential import (
    train_transformations as _train_transformations_sequential,
)
from .common import deepcopy_transformations, recursively_transform
from .convenience import replace_transformation_if_not_drift_native
from .types import Backend, TrainMethod


def train(
    transformations: BlocksOrWrappable,
    X: pd.DataFrame,
    y: pd.Series,
    splitter: Splitter,
    sample_weights: Optional[pd.Series] = None,
    train_method: TrainMethod = TrainMethod.parallel,
    backend: Backend = Backend.no,
) -> TransformationsOverTime:
    """Train a list of transformations over time.

    Args:
        transformations (List[ Union[Transformation, Composite, Model, Callable, BaseEstimator] ]): _description_
        X (pd.DataFrame): _description_
        y (pd.Series): _description_
        splitter (Splitter): _description_
        sample_weights (Optional[pd.Series], optional): _description_. Defaults to None.
        train_method (TrainMethod, optional): _description_. Defaults to TrainMethod.parallel.
        backend (Backend, optional): _description_. Defaults to Backend.no.

    Raises:
        ValueError: _description_

    Returns:
        TransformationsOverTime: _description_
    """

    transformations = wrap_in_list(transformations)
    transformations = replace_transformation_if_not_drift_native(transformations)

    splits = splitter.splits(length=len(y))
    if len(splits) == 0:
        raise ValueError("No splits were generated by the Splitter.")

    if train_method == TrainMethod.parallel and len(splits) > 1:
        process_function = _train_transformations_sequential
        if backend == Backend.ray:
            process_function = _train_transformations_ray

        first_batch_index, first_batch_transformations = process_transformations_window(
            X,
            y,
            sample_weights,
            transformations,
            splits[0],
        )

        rest_idx, rest_transformations = zip(
            *process_function(
                process_transformations_window,
                first_batch_transformations,
                X,
                y,
                sample_weights,
                splits[1:],
            )
        )
        processed_idx = [first_batch_index] + list(rest_idx)
        processed_transformations = [first_batch_transformations] + list(
            rest_transformations
        )

    else:
        processed_idx = []
        processed_transformations = []
        processed_transformation = transformations
        for split in splits:
            processed_id, processed_transformation = process_transformations_window(
                X,
                y,
                sample_weights,
                processed_transformation,
                split,
            )
            processed_idx.append(processed_id)
            processed_transformations.append(processed_transformation)

    return [
        pd.Series(
            transformation_over_time,
            index=processed_idx,
            name=transformation_over_time[0].name,
        )
        for transformation_over_time in zip(*processed_transformations)
    ]


def train_for_deployment(
    transformations: List[
        Union[Transformation, Composite, Model, Callable, BaseEstimator]
    ],
    X: pd.DataFrame,
    y: pd.Series,
    sample_weights: Optional[pd.Series] = None,
) -> DeployableTransformations:

    transformations = wrap_in_list(transformations)
    transformations: Transformations = replace_transformation_if_not_drift_native(
        transformations
    )
    _, transformations = process_transformations_window(
        X, y, sample_weights, transformations, Split(0, 0, None, 0, None)
    )
    return transformations


def process_transformations_window(
    X: pd.DataFrame,
    y: pd.Series,
    sample_weights: Optional[pd.Series],
    transformations: List[Union[Transformation, Composite]],
    split: Split,
) -> Tuple[int, List[Union[Transformation, Composite]]]:

    X_train = X.iloc[split.train_window_start : split.train_window_end]
    y_train = y.iloc[split.train_window_start : split.train_window_end]

    sample_weights_train = (
        sample_weights.iloc[split.train_window_start : split.train_window_end]
        if sample_weights is not None
        else None
    )

    transformations = deepcopy_transformations(transformations)
    X_train = recursively_transform(
        X_train, y_train, sample_weights_train, transformations, fit=True
    )

    return split.model_index, transformations
