{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Fold","text":"FOLD <p>     Fast Adaptive Time Series ML  Engine      This is an internal project - documentation is not updated anymore and substantially differ from the current API. Explore the docs \u00bb </p> <p></p> <p></p> <p>The Adaptive ML Engine that lets you build, deploy and update Models easily. An order of magnitude speed-up, combined with flexibility and rigour. </p> <p></p>"},{"location":"#main-features","title":"Main Features","text":"<ul> <li>10x faster Adaptive Backtesting - What does that mean?</li> <li>Composite Models made Adaptive - What does that mean?</li> <li>Distributed computing - Why is this important?</li> <li>Update deployed models (coming in May) - Why is this important?</li> </ul>"},{"location":"#installation","title":"Installation","text":"<ul> <li> <p>Prerequisites: <code>python &gt;= 3.8</code> and <code>pip</code></p> </li> <li> <p>Install from pypi:   <pre><code>pip install fold-core\n</code></pre></p> </li> </ul>"},{"location":"#quickstart","title":"Quickstart","text":"<p>You can quickly train your chosen models and get predictions by running:</p> <pre><code>from sklearn.ensemble import RandomForestRegressor\nfrom statsforecast.models import ARIMA\nfrom fold import ExpandingWindowSplitter, train_evaluate\nfrom fold.composites import Ensemble\nfrom fold.transformations import OnlyPredictions\nfrom fold.utils.dataset import get_preprocessed_dataset\n\nX, y = get_preprocessed_dataset(\n    \"weather/historical_hourly_la\", target_col=\"temperature\", shorten=1000\n)\n\npipeline = [\n    Ensemble(\n        [\n            RandomForestRegressor(),\n            ARIMA(order=(1, 1, 0)),\n        ]\n    ),\n    OnlyPredictions(),\n]\nsplitter = ExpandingWindowSplitter(initial_train_window=0.2, step=0.2)\nscorecard, prediction, trained_pipelines, _, _ = train_evaluate(pipeline, X, y, splitter)\n</code></pre> <p>(If you install <code>krisi</code> by running <code>pip install krisi</code> you get an extended report back, rather than a single metric.)</p>"},{"location":"#fold-is-different","title":"Fold is different","text":"<ul> <li> <p>Adaptive Models and Backtesting at lightning speed. \u2192 fold allows to simulate and evaluate your models like they would have performed, in reality/when deployed, with clever use of paralellization and design.</p> </li> <li> <p>Create composite models: ensembles, hybrids, stacking pipelines, easily. \u2192 Underutilized, but the easiest, fastest way to increase performance of your Time Series models. </p> </li> <li> <p>Built with Distributed Computing in mind. \u2192 Deploy your research and development pipelines to a cluster with <code>ray</code>, and use <code>modin</code> to handle out-of-memory datasets (full support for modin is coming in April).</p> </li> <li> <p>Bridging the gap between Online and Mini-Batch learning. \u2192 Mix and match <code>xgboost</code> with ARIMA, in a single pipeline. Boost your model's accuracy by updating them on every timestamp, if desired.</p> </li> <li> <p>Update your deployed models, easily, as new data flows in. \u2192 Real world is not static. Let your models adapt, without the need to re-train from scratch.</p> </li> </ul>"},{"location":"#examples-walkthroughs-and-blog-posts","title":"Examples, Walkthroughs and Blog Posts","text":"Name Type Dataset Type Docs Link Colab        \u26a1\ufe0f Core Walkthrough      Walkthrough Energy Notebook Colab       \ud83d\ude84 Speed Comparison of Fold to other libraries      Walkthrough Weather          Notebook                    Colab                \ud83d\udcda Example Collection      Example Weather &amp; Synthetic          Collection Link           -        \ud83d\udd8b\ufe0f Why we ended up building an Adaptive ML engine for Time Series      Blog Public Release Blog Post           Blog post on Applied Exploration            -"},{"location":"#core-features","title":"Core Features","text":"<ul> <li>Supports both Regression and Classification tasks.</li> <li>Online and Mini-batch learning.</li> <li>Feature selection and other transformations on an expanding/rolling window basis</li> <li>Use any scikit-learn/tabular model natively!</li> <li>Use any univariate or sequence models (wrappers provided in fold-wrappers).</li> <li>Use any Deep Learning Time Series models (wrappers provided in fold-wrappers).</li> <li>Super easy syntax!</li> <li>Probabilistic foreacasts (currently, for Classification, full support coming in April).</li> <li>Hyperparemeter optimization / Model selection. (coming in early April!)</li> </ul>"},{"location":"#what-is-adaptive-backtesting","title":"What is Adaptive Backtesting?","text":"<p>It's like classical Backtesting / Time Series Cross-Validation, plus: Inside a test window, and during deployment, fold provides a way for models to update their parameters or access the last value. Learn more</p>"},{"location":"#our-open-core-time-series-toolkit","title":"Our Open-core Time Series Toolkit","text":"<p>Explore our Commercial License options here</p>"},{"location":"#contribution","title":"Contribution","text":"<p>Join our    for live discussion! </p> <p>Submit an issue or reach out to us on info at dream-faster.ai for any inquiries.</p>"},{"location":"#licence-usage","title":"Licence &amp; Usage","text":"<p>We want to bring much-needed transparency, speed and rigour to the process of creating Time Series ML pipelines, while also building a sustainable business, that can support the ecosystem in the long-term. Fold's licence is inbetween source-available and a traditional commercial software licence. It requires a paid licence for any commercial use, after the initial, 30 day trial period.</p> <p>We also want to contribute to open research by giving free access to non-commercial, research use of <code>fold</code>. </p> <p>Read more</p>"},{"location":"#limitations","title":"Limitations","text":"<ul> <li>No intermittent time series support, very limited support for missing values.</li> <li>No hierarchical time series support.</li> </ul>"},{"location":"api/","title":"API","text":"<p>This is the reference guide for <code>fold</code>.</p> <p>The main modules of fold are the following:</p> Module Description Loop and Base classes Contains the main training and backtesting loop Models Naive and Baseline model classes Composites Composite classes that let's your create Composite Models Transformations Transformations"},{"location":"api/composites/","title":"Composites","text":""},{"location":"api/composites/#fold.composites.columns","title":"columns","text":""},{"location":"api/composites/#fold.composites.columns.EnsembleEachColumn","title":"EnsembleEachColumn","text":"<p>             Bases: <code>Composite</code></p> <p>Train a pipeline for each column in the data, then ensemble their results.</p> <p>Parameters:</p> Name Type Description Default <code>pipeline</code> <code>Pipeline</code> <p>Pipeline that get applied to every column, independently, their results then averaged.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.composites import EnsembleEachColumn\n&gt;&gt;&gt; from sklearn.ensemble import RandomForestRegressor\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = EnsembleEachColumn(RandomForestRegressor())\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n</code></pre>"},{"location":"api/composites/#fold.composites.columns.SkipNA","title":"SkipNA","text":"<p>             Bases: <code>Composite</code></p> <p>Skips rows with NaN values in the input data. In the output, rows with NaNs are returned as is, all other rows transformed.</p> <p>Warning: This seriously challenges the continuity of the data, which is very important for traditional time series models. Use with caution, and only with tabular ML models.</p> <p>Parameters:</p> Name Type Description Default <code>pipeline</code> <code>Pipeline</code> <p>Pipeline to run without NA values.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.composites import ModelResiduals\n&gt;&gt;&gt; from sklearn.ensemble import RandomForestClassifier\n&gt;&gt;&gt; from imblearn.under_sampling import RandomUnderSampler\n&gt;&gt;&gt; from fold.utils.tests import generate_zeros_and_ones\n&gt;&gt;&gt; X, y  = generate_zeros_and_ones()\n&gt;&gt;&gt; X[1:100] = np.nan\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = SkipNA(\n...     pipeline=RandomForestClassifier(),\n... )\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n</code></pre>"},{"location":"api/composites/#fold.composites.columns.TransformEachColumn","title":"TransformEachColumn","text":"<p>             Bases: <code>Composite</code></p> <p>Apply a single pipeline to each column, separately.</p> <p>Parameters:</p> Name Type Description Default <code>pipeline</code> <code>Pipeline</code> <p>Pipeline that gets applied to each column</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.composites import TransformEachColumn\n&gt;&gt;&gt; from sklearn.ensemble import RandomForestRegressor\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; X[\"sine_plus_1\"] = X[\"sine\"] + 1.0\n&gt;&gt;&gt; X.head()\n                       sine  sine_plus_1\n2021-12-31 07:20:00  0.0000       1.0000\n2021-12-31 07:21:00  0.0126       1.0126\n2021-12-31 07:22:00  0.0251       1.0251\n2021-12-31 07:23:00  0.0377       1.0377\n2021-12-31 07:24:00  0.0502       1.0502\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = TransformEachColumn(lambda x: x + 1.0)\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; preds.head()\n                       sine  sine_plus_1\n2021-12-31 15:40:00  1.0000       2.0000\n2021-12-31 15:41:00  1.0126       2.0126\n2021-12-31 15:42:00  1.0251       2.0251\n2021-12-31 15:43:00  1.0377       2.0377\n2021-12-31 15:44:00  1.0502       2.0502\n</code></pre>"},{"location":"api/composites/#fold.composites.concat","title":"concat","text":""},{"location":"api/composites/#fold.composites.concat.Concat","title":"Concat","text":"<p>             Bases: <code>Composite</code></p> <p>Concatenates the results of multiple pipelines.</p> <p>Parameters:</p> Name Type Description Default <code>pipelines</code> <code>Pipelines</code> <p>A list of pipelines to be applied to the data, independently of each other.</p> required <code>if_duplicate_keep</code> <code>ResolutionStrategy | str | None</code> <p>How to handle duplicate columns, by default ResolutionStrategy.first</p> <code>first</code> <code>custom_merge_logic</code> <code>Callable[[list[DataFrame]], None] | DataFrame | None</code> <p>A custom function that takes a list of dataframes and returns a single dataframe. If present, it's used instead of ResolutionStrategy.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.composites import Concat\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = Concat([\n...     lambda X: X.assign(sine_plus_1=X[\"sine\"] + 1),\n...     lambda X: X.assign(sine_plus_2=X[\"sine\"] + 2),\n... ])\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; preds.head()\n                     sine_plus_1  sine_plus_2    sine\n2021-12-31 15:40:00       1.0000       2.0000 -0.0000\n2021-12-31 15:41:00       1.0126       2.0126  0.0126\n2021-12-31 15:42:00       1.0251       2.0251  0.0251\n2021-12-31 15:43:00       1.0377       2.0377  0.0377\n2021-12-31 15:44:00       1.0502       2.0502  0.0502\n</code></pre>"},{"location":"api/composites/#fold.composites.concat.Sequence","title":"Sequence","text":"<p>             Bases: <code>Composite</code></p> <p>An optional wrappers that is equivalent to using a single array for the transformations. It executes the transformations sequentially, in the order they are provided.</p> <p>Parameters:</p> Name Type Description Default <code>pipeline</code> <code>Pipelines</code> <p>A list of transformations or models to be applied to the data.</p> required"},{"location":"api/composites/#fold.composites.concat.TransformColumn","title":"TransformColumn","text":"<pre><code>TransformColumn(columns: list[str] | str, pipeline: Pipeline, name: str | None = None) -&gt; Composite\n</code></pre> <p>Transforms a single or multiple columns using the given pipeline.</p>"},{"location":"api/composites/#fold.composites.ensemble","title":"ensemble","text":""},{"location":"api/composites/#fold.composites.ensemble.Ensemble","title":"Ensemble","text":"<p>             Bases: <code>Composite</code></p> <p>Ensemble (average) the results of multiple pipelines.</p> <p>Parameters:</p> Name Type Description Default <code>pipelines</code> <code>Pipelines</code> <p>A list of pipelines to be applied to the data, independently of each other.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.composites import Ensemble\n&gt;&gt;&gt; from fold.models import DummyRegressor\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = Ensemble([\n...     DummyRegressor(0.1),\n...     DummyRegressor(0.9),\n... ])\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; preds.squeeze().head()\n2021-12-31 15:40:00    0.5\n2021-12-31 15:41:00    0.5\n2021-12-31 15:42:00    0.5\n2021-12-31 15:43:00    0.5\n2021-12-31 15:44:00    0.5\nFreq: T, Name: predictions_Ensemble-DummyRegressor-0.1-DummyRegressor-0.9, dtype: float64\n</code></pre>"},{"location":"api/composites/#fold.composites.metalabeling","title":"metalabeling","text":""},{"location":"api/composites/#fold.composites.metalabeling.MetaLabeling","title":"MetaLabeling","text":"<p>             Bases: <code>Composite</code></p> <p>MetaLabeling takes a primary pipeline and a meta pipeline. The primary pipeline is used to predict the target variable. The meta pipeline is used to predict whether the primary model's prediction's are correct (a binary classification problem). It multiplies the probabilities from the meta pipeline with the predictions of the primary pipeline.</p> <p>It's only applicable for binary classification problems, where the labels are either <code>1</code>, <code>-1</code> or one of them are zero.</p> <p>Parameters:</p> Name Type Description Default <code>primary</code> <code>Pipeline</code> <p>A pipeline to be applied to the data. Target (<code>y</code>) is unchanged.</p> required <code>meta</code> <code>Pipeline</code> <p>A pipeline to be applied to predict whether the primary pipeline's predictions are correct. Target (<code>y</code>) is <code>preds == y</code>.</p> required <code>primary_output_included</code> <code> bool</code> <p>Whether the primary pipeline's output is included in the meta pipeline's input, by default False.</p> <code>False</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SingleWindowSplitter\n&gt;&gt;&gt; from fold.composites import MetaLabeling\n&gt;&gt;&gt; from sklearn.ensemble import RandomForestClassifier\n&gt;&gt;&gt; from sklearn.linear_model import LogisticRegression\n&gt;&gt;&gt; from fold.utils.tests import generate_zeros_and_ones\n&gt;&gt;&gt; X, y  = generate_zeros_and_ones()\n&gt;&gt;&gt; splitter = SingleWindowSplitter(train_window=0.5)\n&gt;&gt;&gt; pipeline = MetaLabeling(\n...     primary=LogisticRegression(),\n...     meta=RandomForestClassifier(),\n... )\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n</code></pre> Outputs <pre><code>A prediction is a float between -1 or 0, and 1.\nIt does not output probabilities, as the prediction already includes that information.\n</code></pre> References <p>Meta Labeling (A Toy Example) Meta-Labeling: Theory and Framework</p>"},{"location":"api/composites/#fold.composites.metalabeling_strategy","title":"metalabeling_strategy","text":""},{"location":"api/composites/#fold.composites.residual","title":"residual","text":""},{"location":"api/composites/#fold.composites.residual.ModelResiduals","title":"ModelResiduals","text":"<p>             Bases: <code>Composite</code></p> <p>This is a composite that combines two pipelines: * The primary pipeline is used to predict the target variable. * The meta pipeline is used to predict the primary pipeline's residual (or, error).</p> <p>It adds together the primary pipeline's output with the predicted residual.</p> <p>Also known as: - Residual chasing - Residual boosting - Hybrid approach - \"Moving Average\" in ARIMA</p> <p>It's only applicable for regression tasks.</p> <p>Parameters:</p> Name Type Description Default <code>primary</code> <code>Pipeline</code> <p>A pipeline to be applied to the data. The target (<code>y</code>) is unchanged.</p> required <code>meta</code> <code>Pipeline</code> <p>A pipeline to predict the primary pipeline's residual. The target (<code>y</code>) is the primary pipeline's residual (or, error).</p> required <code>primary_output_included</code> <code>bool</code> <p>Whether the primary pipeline's output is included in the meta pipeline's input, by default False.</p> <code>False</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.composites import ModelResiduals\n&gt;&gt;&gt; from sklearn.ensemble import RandomForestRegressor\n&gt;&gt;&gt; from sklearn.linear_model import LinearRegression\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = ModelResiduals(\n...     primary=LinearRegression(),\n...     meta=RandomForestRegressor(),\n... )\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n</code></pre> References <ul> <li>https://www.kaggle.com/code/ryanholbrook/hybrid-models</li> <li>https://www.uber.com/en-DE/blog/m4-forecasting-competition/</li> </ul>"},{"location":"api/composites/#fold.composites.sample","title":"sample","text":""},{"location":"api/composites/#fold.composites.sample.Sample","title":"Sample","text":"<p>             Bases: <code>Sampler</code></p> <p>Sample data with an imbalanced-learn sampler instance during training. No sampling is done during inference or backtesting.</p> <p>Warning: This seriously challenges the continuity of the data, which is very important for traditional time series models. Use with caution, and only with tabular ML models.</p> <p>Parameters:</p> Name Type Description Default <code>sampler</code> <code>Any</code> <p>An imbalanced-learn sampler instance (subclass of <code>BaseSampler</code>).</p> required <code>pipeline</code> <code>Pipeline</code> <p>A pipeline to be applied to the sampled data.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.composites import ModelResiduals\n&gt;&gt;&gt; from sklearn.ensemble import RandomForestClassifier\n&gt;&gt;&gt; from imblearn.under_sampling import RandomUnderSampler\n&gt;&gt;&gt; from fold.utils.tests import generate_zeros_and_ones_skewed\n&gt;&gt;&gt; X, y  = generate_zeros_and_ones_skewed()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = Sample(\n...     sampler=RandomUnderSampler(),\n...     pipeline=RandomForestClassifier(),\n... )\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n</code></pre> References <p>imbalanced-learn</p>"},{"location":"api/composites/#fold.composites.selectbest","title":"selectbest","text":""},{"location":"api/composites/#fold.composites.target","title":"target","text":""},{"location":"api/composites/#fold.composites.target.TransformTarget","title":"TransformTarget","text":"<p>             Bases: <code>Composite</code></p> <p>Transforms the target within the context of the wrapped Pipeline. <code>wrapped_pipeline</code> will be applied to the input data, where the target (<code>y</code>) is already transformed. <code>y_pipeline</code> will be applied to the target column.</p> <p>The inverse of <code>y_transformation</code> will be applied to the predictions of the primary pipeline.</p> <p>Eg.: Log or Difference transformation.</p> <p>Parameters:</p> Name Type Description Default <code>wrapped_pipeline</code> <code>Pipeline</code> <p>Pipeline, which will be applied to the input data, where the target (<code>y</code>) is already transformed.</p> required <code>y_pipeline</code> <code>list[InvertibleTransformation] | InvertibleTransformation</code> <p>InvertibleTransformations, which will be applied to the target (<code>y</code>)</p> required <code>invert_wrapped_output</code> <code>bool</code> <p>Apply the inverse transformation of <code>y_pipeline</code> to the output of <code>wrapped_pipeline</code>. default is <code>True</code>.</p> <code>True</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.composites import ModelResiduals\n&gt;&gt;&gt; from sklearn.linear_model import LinearRegression\n&gt;&gt;&gt; from fold.transformations import Difference\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = TransformTarget(\n...     wrapped_pipeline=LinearRegression(),\n...     y_pipeline=Difference(),\n... )\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n</code></pre>"},{"location":"api/composites/#fold.composites.utils","title":"utils","text":""},{"location":"api/loop/","title":"Main Loops","text":""},{"location":"api/loop/#fold.loop.encase.backtest_score","title":"backtest_score","text":"<pre><code>backtest_score(trained_pipelines: TrainedPipelineCard, X: pd.DataFrame | None, y: pd.Series, splitter: Splitter, backend: BackendType | Backend | str = BackendType.no, events: EventDataFrame | None = None, silent: bool = False, return_artifacts: bool = False, krisi_args: dict | None = None) -&gt; tuple[ScoreCard, OutOfSamplePredictions] | tuple[ScoreCard, OutOfSamplePredictions, Artifact]\n</code></pre> <p>Run backtest then scoring. <code>krisi</code> is required to be installed.</p> <p>Parameters:</p> Name Type Description Default <code>trained_pipelines</code> <code>TrainedPipelineCard</code> <p>The fitted pipelines, for all folds.</p> required <code>X</code> <code>DataFrame | None</code> <p>Exogenous Data.</p> required <code>y</code> <code>Series</code> <p>Endogenous Data (Target).</p> required <code>splitter</code> <code>Splitter</code> <p>Defines how the folds should be constructed.</p> required <code>backend</code> <code>BackendType | Backend | str</code> <p>The library/service to use for parallelization / distributed computing, by default <code>no</code>.</p> <code>no</code> <code>events</code> <code>EventDataFrame | None</code> <p>Events that should be passed into the pipeline, by default None.</p> <code>None</code> <code>silent</code> <code>bool</code> <p>Wether the pipeline should print to the console, by default False.</p> <code>False</code> <code>return_artifacts</code> <code>bool</code> <p>Whether to return the artifacts of the training process, by default False.</p> <code>False</code> <code>krisi_args</code> <code>dict | None</code> <p>Arguments that will be passed into <code>krisi</code> score function, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>'ScoreCard'</code> <p>A ScoreCard from <code>krisi</code>.</p> <code>OutOfSamplePredictions</code> <p>Predictions for all folds, concatenated.</p>"},{"location":"api/loop/#fold.loop.encase.train_backtest","title":"train_backtest","text":"<pre><code>train_backtest(pipeline: Pipeline | PipelineCard, X: pd.DataFrame | None, y: pd.Series, splitter: Splitter, backend: BackendType | Backend | str = BackendType.no, events: EventDataFrame | None = None, silent: bool = False) -&gt; tuple[OutOfSamplePredictions, TrainedPipelineCard, Artifact, InSamplePredictions]\n</code></pre> <p>Run train and backtest.</p> <p>Parameters:</p> Name Type Description Default <code>pipeline</code> <code>Pipeline | PipelineCard</code> <p>The pipeline to be fitted.</p> required <code>X</code> <code>DataFrame | None</code> <p>Exogenous Data.</p> required <code>y</code> <code>Series</code> <p>Endogenous Data (Target).</p> required <code>splitter</code> <code>Splitter</code> <p>Defines how the folds should be constructed.</p> required <code>backend</code> <code>BackendType | Backend | str</code> <p>The library/service to use for parallelization / distributed computing, by default <code>no</code>.</p> <code>no</code> <code>events</code> <code>EventDataFrame | None</code> <p>Events that should be passed into the pipeline, by default None.</p> <code>None</code> <code>silent</code> <code>bool</code> <p>Wether the pipeline should print to the console, by default False.</p> <code>False</code> <code>return_artifacts</code> <p>Whether to return the artifacts of the process, by default False.</p> required <code>return_insample</code> required <p>Returns:</p> Type Description <code>OutOfSamplePredictions</code> <p>Predictions for all folds, concatenated.</p> <code>TrainedPipelineCard</code> <p>The fitted pipelines, for all folds.</p>"},{"location":"api/loop/#fold.loop.encase.train_evaluate","title":"train_evaluate","text":"<pre><code>train_evaluate(pipeline: Pipeline | PipelineCard, X: pd.DataFrame | None, y: pd.Series, splitter: Splitter, backend: BackendType | Backend | str = BackendType.no, events: EventDataFrame | None = None, silent: bool = False, krisi_args: dict | None = None) -&gt; tuple[ScoreCard, OutOfSamplePredictions, TrainedPipelineCard, Artifact, ScoreCard]\n</code></pre> <p>Run train, backtest then run scoring. <code>krisi</code> needs to be installed.</p> <p>Parameters:</p> Name Type Description Default <code>pipeline</code> <code>Pipeline | PipelineCard</code> <p>The pipeline to be fitted.</p> required <code>X</code> <code>DataFrame | None</code> <p>Exogenous Data.</p> required <code>y</code> <code>Series</code> <p>Endogenous Data (Target).</p> required <code>splitter</code> <code>Splitter</code> <p>Defines how the folds should be constructed.</p> required <code>backend</code> <code>BackendType | Backend | str</code> <p>The library/service to use for parallelization / distributed computing, by default <code>no</code>.</p> <code>no</code> <code>events</code> <code>EventDataFrame | None</code> <p>Events that should be passed into the pipeline, by default None.</p> <code>None</code> <code>silent</code> <code>bool</code> <p>Wether the pipeline should print to the console, by default False.</p> <code>False</code> <code>krisi_args</code> <code>dict | None</code> <p>Arguments that will be passed into <code>krisi</code> score function, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>'ScoreCard'</code> <p>A ScoreCard from <code>krisi</code>.</p> <code>OutOfSamplePredictions</code> <p>Predictions for all folds, concatenated.</p> <code>TrainedPipelineCard</code> <p>The fitted pipelines, for all folds.</p>"},{"location":"api/loop/#fold.loop.training.train","title":"train","text":"<pre><code>train(pipelinecard: PipelineCard | Pipeline, X: pd.DataFrame | None, y: pd.Series, splitter: Splitter, events: EventDataFrame | None = None, backend: BackendType | Backend | str = BackendType.no, silent: bool = False, for_deployment: bool = False) -&gt; tuple[TrainedPipelineCard, Artifact, InSamplePredictions]\n</code></pre> <p>Trains a pipeline on a given dataset, for all folds returned by the Splitter.</p> <p>Parameters:</p> Name Type Description Default <code>pipeline</code> <p>The pipeline to be fitted.</p> required <code>X</code> <code>DataFrame | None</code> <p>Exogenous Data.</p> required <code>y</code> <code>Series</code> <p>Endogenous Data (Target).</p> required <code>splitter</code> <code>Splitter</code> <p>Defines how the folds should be constructed.</p> required <code>backend</code> <code>BackendType | Backend | str</code> <p>The library/service to use for parallelization / distributed computing, by default <code>no</code>.</p> <code>no</code> <code>events</code> <code>EventDataFrame | None</code> <p>Events that should be passed into the pipeline, by default None.</p> <code>None</code> <code>silent</code> <code>bool</code> <p>Wether the pipeline should print to the console, by default False.</p> <code>False</code> <code>return_artifacts</code> <p>Whether to return the artifacts of the training process, by default False.</p> required <code>return_insample</code> <p>Whether to return the in-sample predictions of the training process, by default False.</p> required <code>for_deployment</code> <code>bool</code> <p>Whether the pipeline is being trained for deployment, meaning it'll only have the last fold, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>TrainedPipelineCard</code> <p>The fitted pipelines, for all folds.</p>"},{"location":"api/loop/#fold.loop.backtesting.backtest","title":"backtest","text":"<pre><code>backtest(trained_pipelinecard: TrainedPipelineCard, X: pd.DataFrame | None, y: pd.Series, splitter: Splitter, backend: BackendType | Backend | str = BackendType.no, events: EventDataFrame | None = None, silent: bool = False, mutate: bool = False, return_artifacts: bool = False) -&gt; OutOfSamplePredictions | tuple[OutOfSamplePredictions, Artifact]\n</code></pre> <p>Run backtest on TrainedPipelineCard and given data.</p> <p>Parameters:</p> Name Type Description Default <code>trained_pipelines</code> <p>The fitted pipelines, for all folds.</p> required <code>X</code> <code>DataFrame | None</code> <p>Exogenous Data.</p> required <code>y</code> <code>Series</code> <p>Endogenous Data (Target).</p> required <code>splitter</code> <code>Splitter</code> <p>Defines how the folds should be constructed.</p> required <code>backend</code> <code>BackendType | Backend | str</code> <p>The library/service to use for parallelization / distributed computing, by default <code>no</code>.</p> <code>no</code> <code>sample_weights</code> <p>Weights assigned to each sample/timestamp, that are passed into models that support it, by default None.</p> required <code>events</code> <code>EventDataFrame | None</code> <p>Events that should be passed into the pipeline, by default None.</p> <code>None</code> <code>silent</code> <code>bool</code> <p>Wether the pipeline should print to the console, by default False.</p> <code>False</code> <code>mutate</code> <code>bool</code> <p>Whether <code>trained_pipelines</code> should be mutated, by default False. This is discouraged.</p> <code>False</code> <code>return_artifacts</code> <code>bool</code> <p>Whether to return the artifacts of the backtesting process, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>OutOfSamplePredictions</code> <p>Predictions for all folds, concatenated.</p>"},{"location":"api/loop/#fold.loop.types.BackendType","title":"BackendType","text":"<p>             Bases: <code>ParsableEnum</code></p> <p>Parameters:</p> Name Type Description Default <code>no</code> <p>Uses sequential processing. This is the default.</p> required <code>ray</code> <p>Uses <code>ray</code> as a backend. Call <code>ray.init()</code> before using this backend.</p> required <code>pathos</code> <p>Uses <code>pathos.multiprocessing</code> as a backend (via p_tqdm).</p> required <code>thread</code> <p>Uses <code>threading</code> as a backend (via tqdm.contrib.concurrent.thread_map).</p> required"},{"location":"api/loop/#fold.base.classes","title":"classes","text":""},{"location":"api/loop/#fold.base.classes.InSamplePredictions","title":"InSamplePredictions  <code>module-attribute</code>","text":"<pre><code>InSamplePredictions = DataFrame\n</code></pre> <p>The backtest's resulting in-sample output.</p>"},{"location":"api/loop/#fold.base.classes.OutOfSamplePredictions","title":"OutOfSamplePredictions  <code>module-attribute</code>","text":"<pre><code>OutOfSamplePredictions = DataFrame\n</code></pre> <p>The backtest's resulting out-of-sample output.</p>"},{"location":"api/loop/#fold.base.classes.Pipeline","title":"Pipeline  <code>module-attribute</code>","text":"<pre><code>Pipeline = Block | Sequence[Block]\n</code></pre> <p>A list of <code>fold</code> objects that are executed sequentially. Or a single object.</p>"},{"location":"api/loop/#fold.base.classes.Pipelines","title":"Pipelines  <code>module-attribute</code>","text":"<pre><code>Pipelines = Sequence[Pipeline]\n</code></pre> <p>Multiple, independent <code>Pipeline</code>s.</p>"},{"location":"api/loop/#fold.base.classes.TrainedPipelines","title":"TrainedPipelines  <code>module-attribute</code>","text":"<pre><code>TrainedPipelines = list[Series]\n</code></pre> <p>A list of trained <code>Pipeline</code>s, to be used for backtesting.</p>"},{"location":"api/loop/#fold.base.classes.Composite","title":"Composite","text":"<p>             Bases: <code>Block</code>, <code>Clonable</code>, <code>ABC</code></p> <p>A Composite contains other transformations.</p>"},{"location":"api/loop/#fold.base.classes.Optimizer","title":"Optimizer","text":"<p>             Bases: <code>Block</code>, <code>Clonable</code>, <code>ABC</code></p>"},{"location":"api/loop/#fold.base.classes.Optimizer.get_candidates","title":"get_candidates  <code>abstractmethod</code>","text":"<pre><code>get_candidates(only_traversal: bool) -&gt; list[Pipeline]\n</code></pre> <p>Called iteratively, until an array with a length of zero is returned. Then the loop finishes the candidate evaluation process.</p>"},{"location":"api/loop/#fold.base.classes.Transformation","title":"Transformation","text":"<p>             Bases: <code>Block</code>, <code>ABC</code></p> <p>A transformation is a single step in a pipeline.</p>"},{"location":"api/loop/#fold.base.classes.Transformation.fit","title":"fit  <code>abstractmethod</code>","text":"<pre><code>fit(X: pd.DataFrame, y: pd.Series, sample_weights: pd.Series | None = None, raw_y: pd.Series | None = None) -&gt; Artifact | None\n</code></pre> <p>Called once, with on initial training window.</p>"},{"location":"api/loop/#fold.base.classes.Transformation.update","title":"update  <code>abstractmethod</code>","text":"<pre><code>update(X: pd.DataFrame, y: pd.Series, sample_weights: pd.Series | None = None, raw_y: pd.Series | None = None) -&gt; Artifact | None\n</code></pre> <p>Subsequent calls to update the model.</p>"},{"location":"api/loop/#fold.base.classes.Tunable","title":"Tunable","text":"<p>             Bases: <code>ABC</code></p>"},{"location":"api/loop/#fold.base.classes.Tunable.clone_with_params","title":"clone_with_params","text":"<pre><code>clone_with_params(parameters: dict, clone_children: Callable | None = None) -&gt; Tunable\n</code></pre> <p>The default implementation only works for Transformations, when parameters and the init parameters match 100%.</p>"},{"location":"api/loop/#fold.base.classes.Tunable.get_params","title":"get_params","text":"<pre><code>get_params() -&gt; dict\n</code></pre> <p>The default implementation assumes that: 1. All init parameters are stored on the object as property (with the same name/key). 2. There are no modifications/conversions of the init parameters that'd prevent them from being used again (reconstructing the object from them).</p>"},{"location":"api/loop/#fold.base.scoring","title":"scoring","text":""},{"location":"api/loop/#fold.base.utils","title":"utils","text":""},{"location":"api/loop/#fold.base.utils.traverse","title":"traverse","text":"<pre><code>traverse(pipeline: Pipeline | list[Pipeline])\n</code></pre> <p>Iterates over a pipeline and yields each transformation. CAUTION: It does not \"unroll\" Optimizer's candidates.</p>"},{"location":"api/models/","title":"Models","text":""},{"location":"api/models/#fold.models.base","title":"base","text":""},{"location":"api/models/#fold.models.base.Model","title":"Model","text":"<p>             Bases: <code>Transformation</code></p>"},{"location":"api/models/#fold.models.base.Model.predict","title":"predict  <code>abstractmethod</code>","text":"<pre><code>predict(X: pd.DataFrame) -&gt; pd.Series | pd.DataFrame\n</code></pre> <p>Predictions for exclusively out-of-sample data, the model has never seen before.</p>"},{"location":"api/models/#fold.models.base.Model.predict_in_sample","title":"predict_in_sample  <code>abstractmethod</code>","text":"<pre><code>predict_in_sample(X: pd.DataFrame) -&gt; pd.Series | pd.DataFrame\n</code></pre> <p>Predictions for in-sample, already seen data.</p>"},{"location":"api/models/#fold.models.dummy","title":"dummy","text":""},{"location":"api/models/#fold.models.dummy.DummyClassifier","title":"DummyClassifier","text":"<p>             Bases: <code>Model</code>, <code>Tunable</code></p> <p>A model that predicts a predefined class with predefined probabilities.</p> <p>Parameters:</p> Name Type Description Default <code>predicted_value</code> <code>(float, int)</code> <p>The class to predict.</p> required <code>all_classes</code> <code>list[int]</code> <p>All possible classes.</p> required <code>predicted_probabilities</code> <code>list[float]</code> <p>The probabilities returned.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.models import DummyClassifier\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = DummyClassifier(1, [0, 1], [0.5, 0.5])\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; preds.head()\n                     predictions_DummyClassifier  ...  probabilities_DummyClassifier_1\n2021-12-31 15:40:00                            1  ...                              0.5\n2021-12-31 15:41:00                            1  ...                              0.5\n2021-12-31 15:42:00                            1  ...                              0.5\n2021-12-31 15:43:00                            1  ...                              0.5\n2021-12-31 15:44:00                            1  ...                              0.5\n&lt;BLANKLINE&gt;\n[5 rows x 3 columns]\n</code></pre>"},{"location":"api/models/#fold.models.dummy.DummyRegressor","title":"DummyRegressor","text":"<p>             Bases: <code>Model</code>, <code>Tunable</code></p> <p>A model that predicts a predefined value.</p> <p>Parameters:</p> Name Type Description Default <code>predicted_value</code> <code>float</code> <p>The value to predict.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.models import DummyRegressor\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = DummyRegressor(0.1)\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; preds.head()\n                     predictions_DummyRegressor-0.1\n2021-12-31 15:40:00                             0.1\n2021-12-31 15:41:00                             0.1\n2021-12-31 15:42:00                             0.1\n2021-12-31 15:43:00                             0.1\n2021-12-31 15:44:00                             0.1\n</code></pre>"},{"location":"api/models/#fold.models.random","title":"random","text":""},{"location":"api/models/#fold.models.random.RandomBinaryClassifier","title":"RandomBinaryClassifier","text":"<p>             Bases: <code>Model</code></p> <p>A random model that mimics the probability distribution of the target seen during fitting.</p>"},{"location":"api/models/#fold.models.random.RandomClassifier","title":"RandomClassifier","text":"<p>             Bases: <code>Model</code></p> <p>A model that predicts random classes and probabilities.</p> <p>Parameters:</p> Name Type Description Default <code>all_classes</code> <code>list[int]</code> <p>All possible classes.</p> required <code>probability_mean</code> <code>float</code> <p>The mean of the normal distribution used to generate the probabilities.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.models import RandomClassifier\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; np.random.seed(42)\n&gt;&gt;&gt; pipeline = RandomClassifier([0,1], [0.5, 0.5])\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n</code></pre>"},{"location":"api/models/#fold.models.sklearn","title":"sklearn","text":""},{"location":"api/models/#fold.models.sklearn.WrapSKLearnClassifier","title":"WrapSKLearnClassifier","text":"<p>             Bases: <code>Model</code>, <code>Tunable</code></p> <p>Wraps an SKLearn Classifier model. There's no need to use it directly, <code>fold</code> automatically wraps all sklearn classifiers into this class.</p>"},{"location":"api/models/#fold.models.sklearn.WrapSKLearnRegressor","title":"WrapSKLearnRegressor","text":"<p>             Bases: <code>Model</code>, <code>Tunable</code></p> <p>Wraps an SKLearn regressor model. There's no need to use it directly, <code>fold</code> automatically wraps all sklearn regressors into this class.</p>"},{"location":"api/models/#fold.models.wrappers","title":"wrappers","text":""},{"location":"api/models/#fold.models.wrappers.gbd","title":"gbd","text":""},{"location":"api/transformations/","title":"Transformations","text":""},{"location":"api/transformations/#fold.transformations.columns","title":"columns","text":""},{"location":"api/transformations/#fold.transformations.columns.AddColumnSuffix","title":"AddColumnSuffix","text":"<p>             Bases: <code>Transformation</code></p> <p>Add suffix to column names.</p> <p>Parameters:</p> Name Type Description Default <code>suffix</code> <code>str</code> <p>Suffix to add to all column names.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.transformations import RenameColumns\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = AddColumnSuffix(\"_2\")\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; preds.head()\n                     sine_2\n2021-12-31 15:40:00 -0.0000\n2021-12-31 15:41:00  0.0126\n2021-12-31 15:42:00  0.0251\n2021-12-31 15:43:00  0.0377\n2021-12-31 15:44:00  0.0502\n</code></pre>"},{"location":"api/transformations/#fold.transformations.columns.DropColumns","title":"DropColumns","text":"<p>             Bases: <code>Transformation</code>, <code>Tunable</code></p> <p>Drops a single or multiple columns.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>(list[str], str)</code> <p>The column or columns to drop.</p> required"},{"location":"api/transformations/#fold.transformations.columns.OnlyPredictions","title":"OnlyPredictions","text":"<p>             Bases: <code>Transformation</code></p> <p>Drops all columns except the output model(s)' predictions.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.transformations import OnlyProbabilities\n&gt;&gt;&gt; from fold.models.dummy import DummyClassifier\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = [DummyClassifier(1, [0, 1], [0.5, 0.5]), OnlyPredictions()]\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; preds.head()\n                     predictions_DummyClassifier\n2021-12-31 15:40:00                            1\n2021-12-31 15:41:00                            1\n2021-12-31 15:42:00                            1\n2021-12-31 15:43:00                            1\n2021-12-31 15:44:00                            1\n</code></pre>"},{"location":"api/transformations/#fold.transformations.columns.OnlyProbabilities","title":"OnlyProbabilities","text":"<p>             Bases: <code>Transformation</code></p> <p>Drops all columns except the output model(s)' probabilities.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.transformations import OnlyProbabilities\n&gt;&gt;&gt; from fold.models.dummy import DummyClassifier\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = [DummyClassifier(1, [0, 1], [0.5, 0.5]), OnlyProbabilities()]\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; preds.head()\n                     probabilities_DummyClassifier_0  probabilities_DummyClassifier_1\n2021-12-31 15:40:00                              0.5                              0.5\n2021-12-31 15:41:00                              0.5                              0.5\n2021-12-31 15:42:00                              0.5                              0.5\n2021-12-31 15:43:00                              0.5                              0.5\n2021-12-31 15:44:00                              0.5                              0.5\n</code></pre>"},{"location":"api/transformations/#fold.transformations.columns.RenameColumns","title":"RenameColumns","text":"<p>             Bases: <code>Transformation</code></p> <p>Renames columns.</p> <p>Parameters:</p> Name Type Description Default <code>columns_mapper</code> <code>dict</code> <p>A dictionary containing the old column names as keys and the new column names as values.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.transformations import RenameColumns\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = RenameColumns({\"sine\": \"sine_renamed\"})\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; preds.head()\n                     sine_renamed\n2021-12-31 15:40:00       -0.0000\n2021-12-31 15:41:00        0.0126\n2021-12-31 15:42:00        0.0251\n2021-12-31 15:43:00        0.0377\n2021-12-31 15:44:00        0.0502\n</code></pre>"},{"location":"api/transformations/#fold.transformations.columns.SelectColumns","title":"SelectColumns","text":"<p>             Bases: <code>Transformation</code>, <code>Tunable</code></p> <p>Selects a single or multiple columns, drops the rest.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Union[list[str], str]</code> <p>The column or columns to select (dropping the rest).</p> required"},{"location":"api/transformations/#fold.transformations.dev","title":"dev","text":""},{"location":"api/transformations/#fold.transformations.dev.Breakpoint","title":"Breakpoint","text":"<p>             Bases: <code>Transformation</code></p> <p>A transformation that stops execution at the specified point.</p>"},{"location":"api/transformations/#fold.transformations.difference","title":"difference","text":""},{"location":"api/transformations/#fold.transformations.difference.Difference","title":"Difference","text":"<p>             Bases: <code>Transformation</code>, <code>Tunable</code></p> <p>Takes the returns (percentage change between the current and a prior element).</p> <p>Parameters:</p> Name Type Description Default <code>log_returns</code> <code>bool</code> <p>If True, computes the log returns instead of the simple returns, default False.</p> <code>False.</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.transformations import Difference\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data(freq=\"min\")\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = Difference()\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; X[\"sine\"].loc[preds.index].head()\n2021-12-31 15:40:00   -0.0000\n2021-12-31 15:41:00    0.0126\n2021-12-31 15:42:00    0.0251\n2021-12-31 15:43:00    0.0377\n2021-12-31 15:44:00    0.0502\nFreq: T, Name: sine, dtype: float64\n&gt;&gt;&gt; preds[\"sine\"].head()\n2021-12-31 15:40:00   -1.000000\n2021-12-31 15:41:00        -inf\n2021-12-31 15:42:00    0.992063\n2021-12-31 15:43:00    0.501992\n2021-12-31 15:44:00    0.331565\nFreq: T, Name: sine, dtype: float64\n</code></pre>"},{"location":"api/transformations/#fold.transformations.features","title":"features","text":""},{"location":"api/transformations/#fold.transformations.features.AddFeatures","title":"AddFeatures","text":"<p>             Bases: <code>Transformation</code>, <code>Tunable</code></p> <p>Applies a function to one or more columns.</p> <p>Parameters:</p> Name Type Description Default <code>column_func</code> <code>ColumnFunction | list[ColumnFunction]</code> <p>A tuple of a column or list of columns and a function to apply to them.</p> required <code>fillna</code> <code>bool</code> <p>Fill NaNs in the resulting DataFrame</p> <code>False</code> <code>name</code> <code>str | None</code> <p>Name of the transformation.</p> <code>None</code> <code>params_to_try</code> <code>dict | None</code> <p>Dictionary of parameters to try when tuning.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[pd.DataFrame, Artifact| None]: returns the transformed DataFrame with the original dataframe concatinated.</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.transformations import AddFeatures\n&gt;&gt;&gt; from fold.models.dummy import DummyClassifier\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = AddFeatures([(\"sine\", np.square)])\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; preds.head()\n                       sine  sine~square\n2021-12-31 15:40:00 -0.0000     0.000000\n2021-12-31 15:41:00  0.0126     0.000159\n2021-12-31 15:42:00  0.0251     0.000630\n2021-12-31 15:43:00  0.0377     0.001421\n2021-12-31 15:44:00  0.0502     0.002520\n</code></pre>"},{"location":"api/transformations/#fold.transformations.features.AddWindowFeatures","title":"AddWindowFeatures","text":"<p>             Bases: <code>Transformation</code>, <code>Tunable</code></p> <p>Creates rolling window features on the specified columns. Equivalent to adding a new column by running: <code>df[column].rolling(window).function()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>column_window_func</code> <code>(ColumnWindowFunction, list[ColumnWindowFunction])</code> <p>A list of tuples, where each tuple contains the column name, the window size and the function to apply. The function can be a predefined function (see PredefinedFunction) or a Callable (with a single parameter).</p> required <code>fillna</code> <code>bool</code> <p>Fill NaNs in the resulting DataFrame</p> <code>False</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.transformations import AddWindowFeatures\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = AddWindowFeatures((\"sine\", 10, \"mean\"))\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; preds.head()\n                       sine  sine~mean_10\n2021-12-31 15:40:00 -0.0000      -0.05649\n2021-12-31 15:41:00  0.0126      -0.04394\n2021-12-31 15:42:00  0.0251      -0.03139\n2021-12-31 15:43:00  0.0377      -0.01883\n2021-12-31 15:44:00  0.0502      -0.00628\n</code></pre>"},{"location":"api/transformations/#fold.transformations.function","title":"function","text":""},{"location":"api/transformations/#fold.transformations.function.ApplyFunction","title":"ApplyFunction","text":"<p>             Bases: <code>Transformation</code>, <code>Tunable</code></p> <p>Wraps and arbitrary function that will run at inference.</p>"},{"location":"api/transformations/#fold.transformations.holidays","title":"holidays","text":""},{"location":"api/transformations/#fold.transformations.holidays.AddExchangeHolidayFeatures","title":"AddExchangeHolidayFeatures","text":"<p>             Bases: <code>Transformation</code>, <code>Tunable</code></p> <p>Adds holiday features for given exchange(s) as new column(s). It uses the pattern \"holiday_{exchange}\" for naming the columns.</p> <p>Parameters:</p> Name Type Description Default <code>exchange_codes</code> <code>list[str] | str</code> <p>List of exchange codes  (eg.: <code>NYSE</code>) for which to add holiday features.</p> required <code>labeling</code> <code>str | LabelingMethod</code> <ul> <li>holiday_binary: Workdays = 0 | National Holidays = 1</li> <li>weekday_weekend_holiday: Workdays = 0 | Weekends = 1 | National Holidays == 2</li> </ul> <code>weekday_weekend_holiday</code>"},{"location":"api/transformations/#fold.transformations.holidays.AddHolidayFeatures","title":"AddHolidayFeatures","text":"<p>             Bases: <code>Transformation</code>, <code>Tunable</code></p> <p>Adds holiday features for given region(s) as new column(s). It uses the pattern \"holiday_{country_code}\" for naming the columns.</p> <p>Parameters:</p> Name Type Description Default <code>country_codes</code> <code>list[str] | str</code> <p>List of country codes  (eg.: <code>US</code>, <code>DE</code>) for which to add holiday features.</p> required <code>labeling</code> <code>str | LabelingMethod</code> <ul> <li>holiday_binary: Workdays = 0 | National Holidays = 1</li> <li>weekday_weekend_holiday: Workdays = 0 | Weekends = 1 | National Holidays == 2</li> <li>weekday_weekend_uniqueholiday: Workdays = 0 | Weekends = 1 | National Holidays == Unique int (&gt;1)</li> <li>weekday_weekend_uniqueholiday_string: Workdays = 0 | Weekends = 1 | National Holidays == string</li> </ul> <code>weekday_weekend_holiday</code>"},{"location":"api/transformations/#fold.transformations.holidays.LabelingMethod","title":"LabelingMethod","text":"<p>             Bases: <code>ParsableEnum</code></p> <p>Parameters:</p> Name Type Description Default <code>holiday_binary</code> <ul> <li>Workdays = 0</li> <li>National Holidays = 1</li> </ul> required <code>weekday_weekend_holiday</code> <ul> <li>Workdays = 0</li> <li>Weekends = 1</li> <li>National Holidays == 2</li> </ul> required <code>weekday_weekend_uniqueholiday</code> <ul> <li>Workdays = 0</li> <li>Weekends = 1</li> <li>National Holidays == Unique int (&gt;1)</li> </ul> required <code>weekday_weekend_uniqueholiday_string</code> <ul> <li>Workdays = 0</li> <li>Weekends = 1</li> <li>National Holidays == string</li> </ul> required"},{"location":"api/transformations/#fold.transformations.lags","title":"lags","text":""},{"location":"api/transformations/#fold.transformations.lags.AddLagsX","title":"AddLagsX","text":"<p>             Bases: <code>Transformation</code>, <code>Tunable</code></p> <p>Adds past values of <code>X</code> for the desired column(s).</p> <p>Parameters:</p> Name Type Description Default <code>columns_and_lags</code> <code>(list[ColumnAndLag], ColumnAndLag)</code> <p>A tuple (or a list of tuples) of the column name and a single or a list of lags to add as features.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.transformations import AddLagsX\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = AddLagsX([(\"sine\", 1), (\"sine\", [2,3])])\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; preds.head()\n                       sine  sine~lag_1  sine~lag_2  sine~lag_3\n2021-12-31 15:40:00 -0.0000     -0.0126     -0.0251     -0.0377\n2021-12-31 15:41:00  0.0126     -0.0000     -0.0126     -0.0251\n2021-12-31 15:42:00  0.0251      0.0126     -0.0000     -0.0126\n2021-12-31 15:43:00  0.0377      0.0251      0.0126     -0.0000\n2021-12-31 15:44:00  0.0502      0.0377      0.0251      0.0126\n</code></pre>"},{"location":"api/transformations/#fold.transformations.math","title":"math","text":""},{"location":"api/transformations/#fold.transformations.math.MultiplyBy","title":"MultiplyBy","text":"<p>             Bases: <code>InvertibleTransformation</code>, <code>Tunable</code></p> <p>Multiplies the data by a constant.</p>"},{"location":"api/transformations/#fold.transformations.math.TakeLog","title":"TakeLog","text":"<p>             Bases: <code>InvertibleTransformation</code>, <code>Tunable</code></p> <p>Takes the logarithm of the data.</p> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>(int, str)</code> <p>The base of the logarithm, by default \"e\". Valid values are \"e\", np.e, \"10\", 10, \"2\", 2.</p> <code>'e'</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.transformations import TakeLog\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data(freq=\"min\")\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = TakeLog()\n&gt;&gt;&gt; X[\"sine\"].head()\n2021-12-31 07:20:00    0.0000\n2021-12-31 07:21:00    0.0126\n2021-12-31 07:22:00    0.0251\n2021-12-31 07:23:00    0.0377\n2021-12-31 07:24:00    0.0502\nFreq: T, Name: sine, dtype: float64\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; preds[\"sine\"].head()\n2021-12-31 15:40:00        -inf\n2021-12-31 15:41:00   -4.374058\n2021-12-31 15:42:00   -3.684887\n2021-12-31 15:43:00   -3.278095\n2021-12-31 15:44:00   -2.991740\nFreq: T, Name: sine, dtype: float64\n</code></pre>"},{"location":"api/transformations/#fold.transformations.math.TurnPositive","title":"TurnPositive","text":"<p>             Bases: <code>InvertibleTransformation</code></p> <p>Adds a constant to the data, varying by column, so that all values are positive. It identifies the constant during training, and applies it during inference (and backtesting). Therefore there's no guarantee that the data will be positive during inference (and backtesting).</p> <p>It can not be updated after the initial training, as that'd change the underlying distribution of the data.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.transformations import TurnPositive\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data(freq=\"min\")\n&gt;&gt;&gt; X, y  = X - 1, y - 1\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = TurnPositive()\n&gt;&gt;&gt; X[\"sine\"].head()\n2021-12-31 07:20:00   -1.0000\n2021-12-31 07:21:00   -0.9874\n2021-12-31 07:22:00   -0.9749\n2021-12-31 07:23:00   -0.9623\n2021-12-31 07:24:00   -0.9498\nFreq: T, Name: sine, dtype: float64\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; preds[\"sine\"].head()\n2021-12-31 15:40:00    2.0000\n2021-12-31 15:41:00    2.0126\n2021-12-31 15:42:00    2.0251\n2021-12-31 15:43:00    2.0377\n2021-12-31 15:44:00    2.0502\nFreq: T, Name: sine, dtype: float64\n</code></pre>"},{"location":"api/transformations/#fold.transformations.scaling","title":"scaling","text":""},{"location":"api/transformations/#fold.transformations.scaling.MinMaxScaler","title":"MinMaxScaler","text":"<p>             Bases: <code>WrapInvertibleSKLearnTransformation</code></p> <p>Transform features by scaling each feature to a given range.</p> <p>A wrapper around SKLearn's StandardScaler. Capable of further updates after the initial fit.</p> <p>Parameters:</p> Name Type Description Default <code>feature_range</code> <code>tuple(min, max)</code> <p>Desired range of transformed data.</p> <code>(0, 1)</code> <code>clip</code> <code>bool</code> <p>Set to True to clip transformed values of held-out data to provided <code>feature range</code>.</p> <code>False</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.transformations import MinMaxScaler\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = MinMaxScaler()\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; X[\"sine\"].loc[preds.index].head()\n2021-12-31 15:40:00   -0.0000\n2021-12-31 15:41:00    0.0126\n2021-12-31 15:42:00    0.0251\n2021-12-31 15:43:00    0.0377\n2021-12-31 15:44:00    0.0502\nFreq: T, Name: sine, dtype: float64\n&gt;&gt;&gt; preds[\"sine\"].head()\n2021-12-31 15:40:00    0.50000\n2021-12-31 15:41:00    0.50630\n2021-12-31 15:42:00    0.51255\n2021-12-31 15:43:00    0.51885\n2021-12-31 15:44:00    0.52510\nFreq: T, Name: sine, dtype: float64\n</code></pre> References <p>SKLearn's MinMaxScaler documentation</p>"},{"location":"api/transformations/#fold.transformations.scaling.StandardScaler","title":"StandardScaler","text":"<p>             Bases: <code>WrapInvertibleSKLearnTransformation</code></p> <p>Standardize features by removing the mean and scaling to unit variance.</p> <p>A wrapper around SKLearn's StandardScaler. Capable of further updates after the initial fit.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fold.loop import train_backtest\n&gt;&gt;&gt; from fold.splitters import SlidingWindowSplitter\n&gt;&gt;&gt; from fold.transformations import StandardScaler\n&gt;&gt;&gt; from fold.utils.tests import generate_sine_wave_data\n&gt;&gt;&gt; X, y  = generate_sine_wave_data()\n&gt;&gt;&gt; splitter = SlidingWindowSplitter(train_window=0.5, step=0.2)\n&gt;&gt;&gt; pipeline = StandardScaler()\n&gt;&gt;&gt; X[\"sine\"].head()\n2021-12-31 07:20:00    0.0000\n2021-12-31 07:21:00    0.0126\n2021-12-31 07:22:00    0.0251\n2021-12-31 07:23:00    0.0377\n2021-12-31 07:24:00    0.0502\nFreq: T, Name: sine, dtype: float64\n&gt;&gt;&gt; preds, trained_pipeline, _, _ = train_backtest(pipeline, X, y, splitter)\n&gt;&gt;&gt; preds[\"sine\"].head()\n2021-12-31 15:40:00   -0.000000\n2021-12-31 15:41:00    0.017819\n2021-12-31 15:42:00    0.035497\n2021-12-31 15:43:00    0.053316\n2021-12-31 15:44:00    0.070994\nFreq: T, Name: sine, dtype: float64\n</code></pre> References <p>SKLearn's StandardScaler documentation</p>"},{"location":"api/transformations/#fold.transformations.sklearn","title":"sklearn","text":""},{"location":"api/transformations/#fold.transformations.sklearn.WrapSKLearnFeatureSelector","title":"WrapSKLearnFeatureSelector","text":"<p>             Bases: <code>FeatureSelector</code>, <code>Tunable</code></p> <p>Wraps an SKLearn Feature Selector class, stores the selected columns in <code>selected_features</code> property. There's no need to use it directly, <code>fold</code> automatically wraps all sklearn feature selectors into this class.</p>"},{"location":"api/transformations/#fold.transformations.sklearn.WrapSKLearnTransformation","title":"WrapSKLearnTransformation","text":"<p>             Bases: <code>Transformation</code>, <code>Tunable</code></p> <p>Wraps an SKLearn Transformation. There's no need to use it directly, <code>fold</code> automatically wraps all sklearn transformations into this class.</p>"},{"location":"concepts/adaptive-ml/","title":"Adaptive ML","text":""},{"location":"concepts/adaptive-ml/#what-is-adaptive-ml","title":"What is Adaptive ML?","text":"<p>Time series models that are updated often outperform their static counterparts. You can almost always improve your model's performance with an simple update, by continuously training them as data comes in.</p>"},{"location":"concepts/adaptive-ml/#what-is-adaptive-backtesting","title":"What is Adaptive Backtesting?","text":"<p>With Adaptive Backtesting, you take an existing time series, and train multiple models, as you simulate your model's performance over time:  </p> <p>This way, you can turn almost all of your data into an out of sample test set.</p> <p>Instead of only looking at the last 1 year, 1 month of out-of-sample predictions, you can simulate \"live deployment\" over almost the whole time series.</p>"},{"location":"concepts/adaptive-ml/#how-is-it-different-to-time-series-cross-validation","title":"How is it different to Time Series Cross-Validation?","text":"<p>Inside a test window, and during deployment, <code>fold</code> provides a way for a model to access the last value.  </p> <p>This way, <code>fold</code> blends:</p> <ol> <li> <p>the speed of (Mini-)batch Machine Learning.</p> </li> <li> <p>with the accuracy of Adaptive (or Online) Machine learning. </p> </li> </ol>"},{"location":"concepts/adaptive-ml/#whats-wrong-with-classical-backtesting-time-series-cross-validation","title":"What's wrong with classical Backtesting (\"Time Series Cross-Validation\")?","text":"<p>A simple example with the <code>Naive</code> model (that just repeats the last value):</p> <p>Classical Backtesting</p> <p></p> <p>The model is static, and repeats the last value for the whole test window.</p> <p>Adaptive Backtesting</p> <p></p> <p>The model is up-to-date, and repeats the last value, as you'd expect.</p>"},{"location":"concepts/adaptive-ml/#how-is-that-implemented","title":"How is that implemented?","text":"<p>There are two ways to have a model that's up-to-date:</p> <ol> <li> <p>The model parameters are updated on each timestamp, within the test window. This can be really slow, but a widely available option. See the Speed Comparison section.</p> </li> <li> <p>Give the model special access to the last value, while keeping its parameters constant. This is what <code>fold</code> does with all of our models. This means that the model is still only trained once per fold, providing an order of magnitude speedup, compared to the first method.</p> </li> </ol>"},{"location":"concepts/adaptive-ml/#more","title":"More","text":"<p>The different strategies are implemented with Splitters in <code>fold</code>.</p>"},{"location":"concepts/design/","title":"What are the design decisions that make <code>Fold</code> different?","text":"<p>Ergonomy</p> <ul> <li>There's no explicit \"Pipeline\" class. This allows us to hand back the job of fitting a collection of models to <code>train()</code>. This enables parallelization and reduces duplicate code. See section on Composites.</li> </ul> <p>Bridging the gap between Online and Mini-Batch learning.</p> <ul> <li> <p>We allow both tabular and sequence models, in the same pipeline.</p> </li> <li> <p>We allow both online and mini-batch models, in the same pipeline. If a Model has <code>mode</code> property set to <code>online</code>, the main loop creates an inner \"inference &amp; fit\" loop, so the Model can update its parameters on each timestamp.</p> </li> <li> <p>We also give our \"online\" models a way to access the latest values and skip the step that'd update their parameters. This enables an efficient \"quasi-online\" behaviour, where the model is only re-trained (or, updated) once per fold, but can \"follow\" the time series data - which usually comes with signifcant increase in accuracy.</p> </li> </ul> <p>Built with Distributed Computing in mind</p> <ul> <li>Deploy your research and development pipelines to a cluster with ray, and use modin to handle out-of-memory datasets (full support for modin is coming in April).</li> </ul> <p>First class support for updating deployed models, easily, as new data flows in.</p> <ul> <li>Real world is not static. Let your models adapt, without the need to re-train from scratch.</li> </ul> <p>Specialized in single-step ahead forecasting.</p> <ul> <li>To really cater for the right usecases, <code>fold</code> doesn't support multi-step ahead forecasts, explicitly. See why</li> </ul>"},{"location":"concepts/design/#what-is-the-composite-class","title":"What is the \u201cComposite\u201d class?","text":"<p>We want to keep the \u201cbusiness\u201d of fitting models to the <code>train</code> loop.</p> <p>Composite acts as a \u201cshell\u201d for storing Transformations and combining them in different ways, primarily via the <code>postpocess_results_[primary|secondary]()</code> function.</p> <p>The <code>primary_transformations</code> are fitted first, then optionally, if <code>secondary_transformations</code> are present, the output of both transformations are passed into <code>postprocess_results_secondary()</code>.</p> <p>Composites can also modify <code>X</code> and <code>y</code> via <code>preprocess_[X|y]_[primary|secondary]()</code>.</p> <p>Composites enable us to:</p> <ul> <li>Merge two, entirely different set of Pipelines, like ensembling.</li> <li>Use the result of the first (primary) set of Pipeline in the second Transformations/Pipeline. (like MetaLabeling, or TransformTarget)</li> </ul>"},{"location":"concepts/forecasting-horizon/","title":"There's no explicit of <code>forecasting horizon</code> in fold.","text":"<p><code>fold</code> is fundamentally specialized in single-step ahead (short-term, high frequency) forecasts.</p> <p>While we support models that are built for multi-step ahead foreacsting, the support is implicit: it's the <code>step_size</code> you set on a Splitter. Please see this walkthrough to gain an intuition on how this could be done.</p> <p>To get better long-term forecasts, you can also resample your data, or transform your target (<code>y</code>) to be an aggregate of the next day, week, month or year's values. Based on our experience, you're better off using different models for different time horizons.</p> <p>See a detailed explanation of the different kind of models (and their behaviour) that are available in <code>fold</code> here.</p>"},{"location":"concepts/models/","title":"Models","text":""},{"location":"concepts/models/#model-types-time-series-tabular","title":"Model types (Time series / Tabular)","text":"<p><code>Fold</code> fundamentally supports both:</p>"},{"location":"concepts/models/#time-series-models","title":"\"Time series\" models","text":"<p>The likes of ARIMA, RNNs, Exponential Smoothing, etc.</p> <p>Their univariate variations only have access to <code>y</code>, and ignore all data in <code>X</code>. They're usually designed to be effective without additional feature engineering.</p> <p>Examples:</p> <ul> <li>StatsForecast</li> <li>NeuralForecast</li> <li>Prophet</li> </ul> <p>... provided in fold-wrappers.</p>"},{"location":"concepts/models/#tabular-ml-models","title":"Tabular ML models","text":"<p>The likes of Random Forests, Gradient Boosted Trees, Linear Regression, etc.</p> <p>They depend on having <code>X</code> populated, and do not work as \"univariate\" models. Each row in <code>X</code> corresponds to a single dependent variable, in <code>y</code>.</p> <p>Usually, you may want to add lagged values of <code>y</code> with the AddLagsY class, or create other features for the tabular models with:</p> <ul> <li>AddLagsX: if you have exogenous data already.</li> <li>AddWindowFeatures: if you have exogenous data already, and you want to aggregate them across different windows.</li> </ul> <p>Examples:</p> <ul> <li>Scikit-Learn</li> <li>XGBoost</li> <li>LightGBM</li> </ul> <p>... provided in fold-wrappers.</p> <p>Check out the Examples gallery to see how easy it is to engineer features with <code>fold</code>.</p>"},{"location":"concepts/models/#online-and-mini-batch-learning-modes","title":"Online and Mini-batch Learning Modes","text":"<p>A mini-batch model is retrained for every split the Splitter returns. It can not update its state within a test window, but it may depend on lagged values of <code>X</code> or <code>y</code>.</p> <p>An <code>online</code> model, on the other hand is updated after inference on each timestamp. Except for \"in sample\" predictions, which is done in a batch manner, with <code>predict_in_sample()</code> </p> <p> </p> <p>We also give our \"online\" models a way to access the latest values and skip the step that'd update their parameters. This enables an efficient \"quasi-online\" behaviour, where the model is only re-trained (or, updated) once per fold, but can \"follow\" the time series data - which usually comes with signifcant increase in accuracy.</p>"},{"location":"concepts/models/#baselines","title":"Baselines","text":"<p>As Time Series is a fundamentally hard problem, it's also important to use strong baselines, which we have our own, fast implementations, in fold-models.</p>"},{"location":"concepts/process/","title":"Process","text":"<p>3 step process</p>"},{"location":"concepts/process/#1-information-gathering","title":"1. Information gathering","text":"<p>(coming soon, not fully implemented yet)</p> <ul> <li>Model Selection - \"What's the best model or combination of models?\" </li> <li>Hyperparameter Optimization - \"What hyperparameters to use?\"</li> <li>Feature selection - \"What features to use?\"</li> </ul> <p>These modules are trained only on the first split's \"training window\", then they're static, and can't be updated. The predictions on the first, \"training window\" are always \"in-sample\", as the models have already \"seen\" (were trained on) that data.</p>"},{"location":"concepts/process/#2-model-training","title":"2. Model training","text":"<p>After the initial step is done, we use the information gathered, and train models or transformations on the initial training window. So we don't lose that data.</p> <p>Then, there are two methods to choose from, how to go forward:</p> <ul> <li> <p>Sequentially updating If training mode is sequential, then update the models for each subsequent fold. Plus if model is <code>online</code>, then update the model within the fold as well.</p> </li> <li> <p>Parallel, independent models If training mode is independent, then for each fold, use as many data as possible for the initial training (till <code>train_window_ends</code> for each fold)</p> </li> </ul> <p>It's important, that the results may differ. In the \"Sequentially updating\" scenario, the model may be stuck in some kind of local optima, while the \"Parallel, independent models\" always starts model training from scratch. \"Sequentially updating\" mode is conceptually incompatible with SlidingWindowSplitter.</p>"},{"location":"concepts/process/#3-inference","title":"3. Inference","text":"<p>Always sequentially updating</p>"},{"location":"concepts/speed/","title":"Speed","text":"<ol> <li>SKTime vs fold</li> </ol> <p><code>fold</code> is 3-100x faster than SKTime in Adaptive Backtesting.</p>"},{"location":"concepts/splitters/","title":"Splitters","text":""},{"location":"concepts/splitters/#expanding-window","title":"Expanding Window","text":"<p>Uses all data up until the current split date.</p>"},{"location":"concepts/splitters/#sliding-window","title":"Sliding Window","text":"<p>Useful when you want to limit how much long models should look \"into the past\".</p>"},{"location":"concepts/splitters/#single-train-test-split","title":"Single train-test split","text":"<p>If you are not convinced of the usefulness of Adaptive ML, feel free to use the classical single train-test split. The downside is that you throw away data that can be used as your test set.</p>"},{"location":"generated/gallery/","title":"Examples","text":""},{"location":"generated/gallery/#readme","title":"Readme","text":"<p> Adding Date/Time Features </p> <p> Preprocessing </p> <p> Using Tabular Models </p> <p> Scaling the data </p> <p> Transformations applied to the Target (y) </p> <p> Ensembling (Composite Models) </p> <p> Download all examples in Python source code: gallery_python.zip</p> <p> Download all examples in Jupyter notebooks: gallery_jupyter.zip</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/date/","title":"Adding Date/Time Features","text":"<p>Note</p> <p>Click here to download the full example code or to run this example in your browser via Binder</p>"},{"location":"generated/gallery/date/#adding-datetime-features","title":"Adding Date/Time Features","text":"<pre><code># mkdocs_gallery_thumbnail_path = 'images/example_thumnail.png'\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom fold.loop import train_evaluate\nfrom fold.splitters import ExpandingWindowSplitter\nfrom fold.transformations import AddDateTimeFeatures, AddHolidayFeatures\nfrom fold.utils.dataset import get_preprocessed_dataset\n\nX, y = get_preprocessed_dataset(\n    \"weather/historical_hourly_la\", target_col=\"temperature\", shorten=1000\n)\n\nsplitter = ExpandingWindowSplitter(initial_train_window=0.2, step=0.1)\npipeline = [\n    AddDateTimeFeatures([\"hour\", \"day_of_week\"]),\n    AddHolidayFeatures([\"US\"]),\n    RandomForestRegressor(),\n]\n\nscorecard, prediction, trained_pipelines = train_evaluate(pipeline, X, y, splitter)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p></p> <p> Download Python source code: date.py</p> <p> Download Jupyter notebook: date.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/ensembling/","title":"Ensembling (Composite Models)","text":"<p>Note</p> <p>Click here to download the full example code or to run this example in your browser via Binder</p>"},{"location":"generated/gallery/ensembling/#ensembling-composite-models","title":"Ensembling (Composite Models)","text":"<pre><code>from statsforecast.models import ARIMA\nfrom xgboost import XGBRegressor\n\nfrom fold.composites import Concat, Ensemble\nfrom fold.loop import train_evaluate\n\n# mkdocs_gallery_thumbnail_path = 'images/example_thumnail.png'\nfrom fold.models.wrappers import WrapStatsForecast\nfrom fold.splitters import ExpandingWindowSplitter\nfrom fold.transformations import AddLagsX, AddWindowFeatures, Difference\nfrom fold.utils.dataset import get_preprocessed_dataset\n\nX, y = get_preprocessed_dataset(\n    \"weather/historical_hourly_la\", target_col=\"temperature\", shorten=1000\n)\n\nsplitter = ExpandingWindowSplitter(initial_train_window=0.2, step=0.1)\npipeline_tabular = [\n    Difference(),\n    Concat(\n        [\n            AddWindowFeatures([(\"temperature\", 14, \"mean\")]),\n            AddLagsX(columns_and_lags=[(\"temperature\", list(range(1, 5)))]),\n        ]\n    ),\n    XGBRegressor(),\n]\npipeline_arima = WrapStatsForecast(ARIMA, {\"order\": (1, 1, 0)}, use_exogenous=False)\nensemble = Ensemble([pipeline_tabular, pipeline_arima])\n\nscorecard, prediction, trained_pipelines = train_evaluate(ensemble, X, y, splitter)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p></p> <p> Download Python source code: ensembling.py</p> <p> Download Jupyter notebook: ensembling.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/preprocess/","title":"Preprocessing","text":"<p>Note</p> <p>Click here to download the full example code or to run this example in your browser via Binder</p>"},{"location":"generated/gallery/preprocess/#preprocessing","title":"Preprocessing","text":"<pre><code># mkdocs_gallery_thumbnail_path = 'images/example_thumnail.png'\nfrom fold import train\nfrom fold.composites import Concat\nfrom fold.splitters import ExpandingWindowSplitter\nfrom fold.transformations import AddLagsX, AddLagsY, AddWindowFeatures, Difference\nfrom fold.utils.dataset import get_preprocessed_dataset\n\nX, y = get_preprocessed_dataset(\n    \"weather/historical_hourly_la\",\n    target_col=\"temperature\",\n)\n\nsplitter = ExpandingWindowSplitter(initial_train_window=0.2, step=0.1)\npipeline = [\n    Difference(),\n    Concat(\n        [\n            AddWindowFeatures([(\"temperature\", 14, \"mean\")]),\n            AddLagsX(columns_and_lags=[(\"temperature\", list(range(1, 5)))]),\n            AddLagsY([1, 2]),\n        ]\n    ),\n]\n\n\ntrained_pipelines = train(pipeline, X, y, splitter)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p></p> <p> Download Python source code: preprocess.py</p> <p> Download Jupyter notebook: preprocess.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/scale/","title":"Scaling the data","text":"<p>Note</p> <p>Click here to download the full example code or to run this example in your browser via Binder</p>"},{"location":"generated/gallery/scale/#scaling-the-data","title":"Scaling the data","text":"<pre><code># mkdocs_gallery_thumbnail_path = 'images/example_thumnail.png'\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom fold.composites import TransformTarget\nfrom fold.loop import train_evaluate\nfrom fold.splitters import ExpandingWindowSplitter\nfrom fold.transformations import AddWindowFeatures, StandardScaler\nfrom fold.utils.dataset import get_preprocessed_dataset\n\nX, y = get_preprocessed_dataset(\n    \"weather/historical_hourly_la\", target_col=\"temperature\", shorten=1000\n)\n\nsplitter = ExpandingWindowSplitter(initial_train_window=0.2, step=0.1)\npipeline = [\n    TransformTarget(\n        [\n            StandardScaler(),\n            AddWindowFeatures([(\"temperature\", 14, \"mean\")]),\n            RandomForestRegressor(),\n        ],\n        StandardScaler(),\n    )\n]\n\nscorecard, prediction, trained_pipelines = train_evaluate(pipeline, X, y, splitter)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p></p> <p> Download Python source code: scale.py</p> <p> Download Jupyter notebook: scale.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/tabular/","title":"Using Tabular Models","text":"<p>Note</p> <p>Click here to download the full example code or to run this example in your browser via Binder</p>"},{"location":"generated/gallery/tabular/#using-tabular-models","title":"Using Tabular Models","text":"<pre><code># mkdocs_gallery_thumbnail_path = 'images/example_thumnail.png'\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom fold.composites import Concat\nfrom fold.loop import train_evaluate\nfrom fold.splitters import ExpandingWindowSplitter\nfrom fold.transformations import AddLagsX, AddWindowFeatures\nfrom fold.utils.dataset import get_preprocessed_dataset\n\nX, y = get_preprocessed_dataset(\n    \"weather/historical_hourly_la\", target_col=\"temperature\", shorten=1000\n)\n\nsplitter = ExpandingWindowSplitter(initial_train_window=0.2, step=0.1)\npipeline = [\n    Concat(\n        [\n            AddWindowFeatures([(\"temperature\", 14, \"mean\")]),\n            AddLagsX(columns_and_lags=[(\"temperature\", list(range(1, 5)))]),\n        ]\n    ),\n    RandomForestRegressor(),\n]\n\nscorecard, prediction, trained_pipelines = train_evaluate(pipeline, X, y, splitter)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p></p> <p> Download Python source code: tabular.py</p> <p> Download Jupyter notebook: tabular.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/transform-target/","title":"Transformations applied to the Target (y)","text":"<p>Note</p> <p>Click here to download the full example code or to run this example in your browser via Binder</p>"},{"location":"generated/gallery/transform-target/#transformations-applied-to-the-target-y","title":"Transformations applied to the Target (y)","text":"<pre><code># mkdocs_gallery_thumbnail_path = 'images/example_thumnail.png'\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom fold.composites import Concat, TransformTarget\nfrom fold.loop import train_evaluate\nfrom fold.splitters import ExpandingWindowSplitter\nfrom fold.transformations import AddLagsX, AddWindowFeatures, Difference\nfrom fold.utils.dataset import get_preprocessed_dataset\n\nX, y = get_preprocessed_dataset(\n    \"weather/historical_hourly_la\", target_col=\"temperature\", shorten=1000\n)\n\nsplitter = ExpandingWindowSplitter(initial_train_window=0.2, step=0.1)\npipeline = TransformTarget(\n    [\n        Difference(),\n        Concat(\n            [\n                AddWindowFeatures([(\"temperature\", 14, \"mean\")]),\n                AddLagsX(columns_and_lags=[(\"temperature\", list(range(1, 5)))]),\n            ]\n        ),\n        RandomForestRegressor(),\n    ],\n    Difference(),\n)\n\nscorecard, prediction, trained_pipelines = train_evaluate(pipeline, X, y, splitter)\n</code></pre> <p>Total running time of the script: ( 0 minutes  0.000 seconds)</p> <p></p> <p> Download Python source code: transform-target.py</p> <p> Download Jupyter notebook: transform-target.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"product/license/","title":"License","text":"<pre><code>                        LICENSE\n</code></pre> <p>Copyright (c) 2022 - present Myalo UG (haftungbeschr\u00e4nkt)  (Mark Aron Szulyovszky, Daniel Szemerey) info@dreamfaster.ai</p> <p>Software: fold (https://www.github.com/dream-faster/fold) Licensor: Myalo UG (haftungsbeschr\u00e4nkt), Berlin, Germany</p> <pre><code>                        PREAMBLE\n</code></pre> <p>The goal of this license is to contribute to the advance of Time-Series  and Nowcasting Research by granting access to this software for non-commercial use. For Commercial use or Commercial Entities  or Public Entities (with the exceptions below)  a license has to be purchased from the Licensor.</p> <pre><code>                   TERMS AND CONDITIONS\n</code></pre> <p>The Licensor hereby grants non-commercial entities the right  to copy, modify, create derivative works, redistribute, and make non-commercial  use of the Licensed Work. The Licensor may make an Additional Use Grant,  above, permitting commercial use. </p> <p>Public (Government) and Commercial entities are required to purchase a license or  apply and receive a non-profit exception, unless the use is for physical  or mental health care, family and social services, social welfare,  senior care, child care, and the care of persons with disabilities.</p> <p>A trial period of thirty (30) days is granted for all, after which the Licensed Work can only be used if in complicance with the  License Terms and Conditions.</p> <p>If your use of the Licensed Work does not comply with the requirements  currently in effect as described in this License, you must purchase a  commercial license from the Licensor, its affiliated entities, or  authorized resellers, or you must refrain from using the Licensed Work.</p> <p>All copies of the original and modified Licensed Work, and derivative  works of the Licensed Work, are subject to this License.</p> <p>You must conspicuously display this License on each original or modified  copy of the Licensed Work. If you receive the Licensed Work in original  or modified form from a third party, the terms and conditions set forth  in this License apply to your use of that work.</p> <p>Without limiting other conditions in the License, the grant of rights  under the License will not include, and the License does not grant to you,  the right to Sell the Software.</p> <p>For purposes of the foregoing, \u201cSell\u201d means practicing any or all of the  rights granted to you under the License to provide to third parties,  for a fee or other consideration (including without limitation fees for hosting or support services related to the Software), a product or  service whose value derives, entirely or substantially, from the functionality  of the Software. </p> <pre><code>                    DISCLAIMER OF WARRANTY\n</code></pre> <p>THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.</p> <pre><code>                    LIMITATION OF LIABILITY\n</code></pre> <p>IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.</p>"},{"location":"product/pricing/","title":"Pricing","text":"Commercial license for Fold \u23e9 Fast Adaptive Backtesting \u23e9 Fast Backtesting with Continuous Validation \u23e9 Deployment to Production Contact Us"},{"location":"product/roadmap/","title":"Roadmap","text":"<p>We\u2019re building:</p> <ul> <li> <p>A package that helps you deploy your <code>fold</code> pipelines.</p> </li> <li> <p>Our own implementation of new and classic time series models, providing an additional order of magnitude speedup during backtesting (while supporting online updates when deployed).</p> </li> <li> <p>Time Series AutoML without lookahead bias, to get accurate simulated performance on past data that you can rely on.</p> </li> <li> <p>Training models on multiple time series at the same time, with synchronized Adaptive Models.</p> </li> <li> <p>Full support for Uncertainty Quantification, making it an internal part of Fold.</p> </li> </ul> <p>And many more\u2026</p>"},{"location":"walkthroughs/benchmarking_sktime_fold/","title":"Benchmarking the speed of fold and SKTime.","text":"<p>  Download   Open In Colab</p> <p></p>"},{"location":"walkthroughs/benchmarking_sktime_fold/#installing-libraries-defining-utility-functions","title":"Installing libraries, defining utility functions","text":"<pre><code>%%capture\npip install --quiet fold-core fold-models krisi fold-wrappers matplotlib seaborn xgboost plotly prophet statsforecast statsmodels ray kaleido sktime pmdarima\n</code></pre> <pre><code>from time import monotonic\nimport pandas as pd\nfrom collections import defaultdict\nfrom krisi import score\nfrom krisi.report import plot_y_predictions\nimport plotly.io as pio\npio.renderers.default = \"png\"\n\nclass Timing:\n    results = defaultdict(lambda: defaultdict(dict))\n\n    def record_time(self, model_name: str, framework: str):\n        def wrapper( function, *args, **kwargs):\n            start_time = monotonic()\n            return_value = function(*args, **kwargs)\n            print(f\"Run time: {monotonic() - start_time} seconds\")\n\n            self.results[framework][model_name] = monotonic() - start_time\n            return return_value\n        return wrapper\n    def summary(self):\n        pd.set_option('display.max_rows', None)\n        pd.set_option('display.max_columns', None)\n        pd.set_option('display.colheader_justify', 'center')\n        pd.set_option('display.precision', 3)\n        display(pd.DataFrame(self.results))\n\ntiming = Timing()\n\ndef flatten_result_windows(series: pd.Series) -&gt; pd.Series:\n    return pd.concat(series.to_list())\n</code></pre>"},{"location":"walkthroughs/benchmarking_sktime_fold/#data-loading","title":"Data Loading","text":"<pre><code>from fold.utils.dataset import get_preprocessed_dataset\n\nX, y = get_preprocessed_dataset(\n    \"weather/historical_hourly_la\", target_col=\"temperature\", resample=\"H\", shorten=1000\n)\n\nprint(X.head());\nprint(y.head());\npd.concat([y,X], axis='columns').plot(subplots=True);\n</code></pre> <pre><code>                     humidity  pressure  wind_speed  wind_direction  \\\ndatetime                                                              \n2012-10-01 13:00:00      88.0    1013.0         0.0             0.0   \n2012-10-01 14:00:00      88.0    1013.0         0.0             0.0   \n2012-10-01 15:00:00      88.0    1013.0         0.0             0.0   \n2012-10-01 16:00:00      88.0    1013.0         0.0             0.0   \n2012-10-01 17:00:00      88.0    1013.0         0.0             0.0\n\n                     temperature  \ndatetime                          \n2012-10-01 13:00:00   291.870000  \n2012-10-01 14:00:00   291.868186  \n2012-10-01 15:00:00   291.862844  \n2012-10-01 16:00:00   291.857503  \n2012-10-01 17:00:00   291.852162  \ndatetime\n2012-10-01 13:00:00    291.868186\n2012-10-01 14:00:00    291.862844\n2012-10-01 15:00:00    291.857503\n2012-10-01 16:00:00    291.852162\n2012-10-01 17:00:00    291.846821\nFreq: H, Name: temperature, dtype: float64\n</code></pre> <pre><code># Default values that both sktime and fold will receive\n\nstep_size = 50\ninitial_train_size = 300\nlag_length_for_tabular_models = 10\nfh=list(range(1, step_size+1))\n</code></pre>"},{"location":"walkthroughs/benchmarking_sktime_fold/#sktime-long-forecasting-horizon-time-series-cross-validation","title":"SKTime - Long forecasting horizon (Time Series Cross-Validation)","text":"<pre><code>from sktime.forecasting.model_evaluation import evaluate\nfrom sktime.forecasting.model_selection import ExpandingWindowSplitter as SKTimeExpandingWindowSplitter\nfrom sktime.forecasting.naive import NaiveForecaster\nfrom sktime.forecasting.arima import ARIMA\nfrom sktime.pipeline import make_pipeline\nfrom sktime.forecasting.compose import make_reduction\n</code></pre> <pre><code>cv = SKTimeExpandingWindowSplitter(initial_window=initial_train_size, step_length=step_size, fh=fh)\n</code></pre>"},{"location":"walkthroughs/benchmarking_sktime_fold/#naive","title":"Naive","text":"<pre><code>forecaster = NaiveForecaster(strategy=\"last\")\nresults = timing.record_time('naive', 'sktime (long-fh)')(evaluate, forecaster=forecaster, y=y, X=X, cv=cv, return_data=True, error_score='raise')\npredictions = flatten_result_windows(results['y_pred']).rename(\"naive\")\nplot_y_predictions(y[predictions.index], predictions.to_frame(), mode=\"overlap\")\nscore(y[predictions.index], predictions)[['rmse']].print('minimal')\n</code></pre> <pre><code>Run time: 0.32869669699999804 seconds\n</code></pre> <pre>                                            naive\n                 Root Mean Squared Error  5.36894\n</pre>"},{"location":"walkthroughs/benchmarking_sktime_fold/#statsmodels-arima","title":"Statsmodels ARIMA","text":"<pre><code>forecaster = ARIMA((1,1,0))\n\nresults = timing.record_time('arima', 'sktime (long-fh)')(evaluate, forecaster=forecaster, y=y, cv=cv, return_data=True, error_score='raise')\npredictions = flatten_result_windows(results['y_pred'])\nplot_y_predictions(y[predictions.index], predictions.to_frame(), mode=\"overlap\")\nscore(y[predictions.index], predictions)[['rmse']].print('minimal')\n</code></pre> <pre><code>Run time: 2.449221571999999 seconds\n</code></pre> <pre>                                          temperature\n                 Root Mean Squared Error     6.743475\n</pre> <p>A seasonal ARIMA - not suprisingly - provides much better results, but because of the slowness (and out of memory errors), we couldn't benchmark Statsmodels' implementation.</p>"},{"location":"walkthroughs/benchmarking_sktime_fold/#xgboost","title":"XGBoost","text":"<pre><code>from xgboost import XGBRegressor\nregressor = XGBRegressor(random_state=42)\n\nforecaster = make_reduction(regressor, strategy=\"recursive\", window_length=lag_length_for_tabular_models)\nresults = timing.record_time('xgboost', 'sktime (long-fh)')(evaluate, forecaster=forecaster, y=y, X=X, cv=cv, backend=\"multiprocessing\", return_data=True, error_score='raise')\npredictions = flatten_result_windows(results['y_pred'])\nplot_y_predictions(y[predictions.index], predictions.to_frame(), mode=\"overlap\")\nscore(y[predictions.index], predictions)[['rmse']].print('minimal')\n</code></pre> <pre><code>Run time: 44.59098899100002 seconds\n</code></pre> <pre>                                          temperature\n                 Root Mean Squared Error     5.044424\n</pre>"},{"location":"walkthroughs/benchmarking_sktime_fold/#results","title":"Results","text":"<pre><code>timing.summary()\n</code></pre> sktime (long-fh) arima 2.449 naive 0.329 xgboost 44.591 <p>SKTime may look fast on its own, but it definitely falls short when it comes to the real usefulness of Time Series Cross-Validation.</p> <p>The models are static, stuck in the past between end of the training windows, they don't have access to the latest value, and therefore their predictions are way off.</p>"},{"location":"walkthroughs/benchmarking_sktime_fold/#fold-short-forecasting-horizon-continuous-validation","title":"Fold - Short forecasting horizon (Continuous Validation)","text":"<p>fold has the ability to update models within the test window, in an \"online\" manner:</p> <p></p> <pre><code>from fold import train_evaluate, ExpandingWindowSplitter, BackendType\nfrom fold.transformations import AddLagsX\nfrom fold.models.wrappers import WrapXGB, WrapStatsModels\nfrom fold.models import Naive\nfrom statsmodels.tsa.arima.model import ARIMA as StatsModelARIMA\nimport ray\nray.init(ignore_reinit_error=True)\n</code></pre> <pre><code>2023-04-17 11:07:04,950 INFO worker.py:1553 -- Started a local Ray instance.\n</code></pre> Ray Python version: 3.9.16 Ray version:  2.3.1 <pre><code>splitter = ExpandingWindowSplitter(initial_train_window=initial_train_size, step=step_size) \n</code></pre>"},{"location":"walkthroughs/benchmarking_sktime_fold/#naive_1","title":"Naive","text":"<pre><code>model = Naive()\n\nscorecard, predictions, _ = timing.record_time('naive', 'fold (online)')(train_evaluate, model, None, y, splitter, backend=BackendType.no, silent=True)\nplot_y_predictions(y[predictions.index], predictions, mode=\"overlap\")\nscorecard[['rmse']].print('minimal')\n</code></pre> <pre><code>Run time: 0.17832120899998927 seconds\n</code></pre> <pre>                                          predictions_Naive\n                 Root Mean Squared Error        1.224      \n</pre>"},{"location":"walkthroughs/benchmarking_sktime_fold/#statsmodels-arima-online","title":"Statsmodels ARIMA (Online)","text":"<pre><code>model = WrapStatsModels(StatsModelARIMA, init_args=dict(order=(1, 1, 0)), online_mode=True)\nscorecard, predictions, _ = timing.record_time('arima', 'fold (online)')(train_evaluate, model, None, y, splitter, backend=BackendType.no, silent=True)\nplot_y_predictions(y[predictions.index], predictions, mode=\"overlap\")\nscorecard[['rmse']].print('minimal')\n</code></pre> <pre><code>Run time: 41.32513004100002 seconds\n</code></pre> <pre>                                          predictions_WrapStatsModels-type\n                 Root Mean Squared Error                0.927             \n</pre>"},{"location":"walkthroughs/benchmarking_sktime_fold/#xgboost_1","title":"XGBoost","text":"<pre><code>from xgboost import XGBRegressor\nmodel = XGBRegressor(random_state=42)\npipeline = [AddLagsX((\"all\", list(range(lag_length_for_tabular_models))) ), model]\n\nscorecard, predictions, _ = timing.record_time('xgboost', 'fold (online)')(train_evaluate, pipeline, X, y, splitter, backend=BackendType.ray, silent=True)\nplot_y_predictions(y[predictions.index], predictions, mode=\"overlap\")\nscorecard[['rmse']].print('minimal')\n</code></pre> <p>This results in much more realistic simulation of past performance (in case the last value is available in production).</p>"},{"location":"walkthroughs/benchmarking_sktime_fold/#results_1","title":"Results","text":"<pre><code>timing.summary()\n</code></pre> sktime (long-fh) fold (online) naive 0.329 0.180 arima 2.449 41.325 xgboost 44.591 13.256 <p>And it's also substantially faster, except in the case of Statsmodels' ARIMA, which <code>fold</code> needs to update on every timestamp. Our own ARIMA (coming in April) will provide a ca. 100x speedup here.</p>"},{"location":"walkthroughs/benchmarking_sktime_fold/#sktime-short-forecasting-horizon-continuous-validation","title":"SKTime - Short forecasting horizon (Continuous Validation)","text":"<pre><code>cv = SKTimeExpandingWindowSplitter(initial_window=initial_train_size, step_length=1, fh=1)\n</code></pre> <p>Now let's see what SKTime's training speed would be like if we wanted to replicate \"Continuous Validation\", and the models having access to the latest value within the folds.</p> <p>This means we'll need to update (not possible with the tested models) or fit a new model for every timestamp we return.</p>"},{"location":"walkthroughs/benchmarking_sktime_fold/#naive_2","title":"Naive","text":"<pre><code>forecaster = NaiveForecaster(strategy=\"last\")\nresults = timing.record_time('naive', 'sktime (online)')(evaluate, forecaster=forecaster, y=y, X=X, cv=cv, return_data=True, strategy=\"refit\", error_score='raise')\npredictions = flatten_result_windows(results['y_pred']).rename(\"naive\")\nplot_y_predictions(y[predictions.index], predictions.to_frame(), mode=\"overlap\")\nscore(y[predictions.index], predictions)[['rmse']].print('minimal')\n</code></pre> <pre><code>Run time: 18.046849753999993 seconds\n</code></pre> <pre>                                          naive\n                 Root Mean Squared Error  1.224\n</pre>"},{"location":"walkthroughs/benchmarking_sktime_fold/#statsmodels-arima_1","title":"Statsmodels ARIMA","text":"<pre><code>from sktime.forecasting.arima import ARIMA\nforecaster = ARIMA((1,1,0))\n\nresults = timing.record_time('arima', 'sktime (online)')(evaluate, forecaster=forecaster, y=y, cv=cv, return_data=True, error_score='raise')\npredictions = flatten_result_windows(results['y_pred'])\nplot_y_predictions(y[predictions.index], predictions.to_frame(), mode=\"overlap\")\nscore(y[predictions.index], predictions)[['rmse']].print('minimal')\n</code></pre> <pre><code>/usr/local/lib/python3.9/dist-packages/statsmodels/base/model.py:604: ConvergenceWarning:\n\nMaximum Likelihood optimization failed to converge. Check mle_retvals\n\n\n\nRun time: 106.65218957599996 seconds\n</code></pre> <pre>                                          temperature\n                 Root Mean Squared Error     0.927   \n</pre>"},{"location":"walkthroughs/benchmarking_sktime_fold/#xgboost_2","title":"XGBoost","text":"<pre><code>from xgboost import XGBRegressor\nregressor = XGBRegressor(random_state=42)\n\nforecaster = make_reduction(regressor, strategy=\"recursive\", window_length=lag_length_for_tabular_models)\nresults = timing.record_time('xgboost', 'sktime (online)')(evaluate, forecaster=forecaster, y=y, X=X, cv=cv, backend=None, return_data=True, error_score='raise')\npredictions = flatten_result_windows(results['y_pred'])\nplot_y_predictions(y[predictions.index], predictions.to_frame(), mode=\"overlap\")\nscore(y[predictions.index], predictions)[['rmse']].print('minimal')\n</code></pre> <pre><code>Run time: 759.161927353 seconds\n</code></pre> <pre>                                          temperature\n                 Root Mean Squared Error     1.018   \n</pre>"},{"location":"walkthroughs/benchmarking_sktime_fold/#overall-results","title":"Overall Results","text":"<pre><code>timing.summary()\n</code></pre> sktime (long-fh) fold (online) sktime (online) naive 0.329 0.180 18.048 arima 2.449 41.325 106.653 xgboost 44.591 13.256 759.163 <p>Overall, <code>fold</code> provides a speedup between 3x and 100x, already.</p> <p>When it comes to practice, we argue that this makes Continuos Validation feasible, compared to other tools out there.</p>"},{"location":"walkthroughs/core_walkthrough/","title":"Fold - Core Walkthrough","text":"<p> Download   Open In Colab</p> <p></p> <p>Welcome \ud83d\udc4b</p> <p>In this notebook we'll demonstrate <code>fold</code>'s powerful interface for creating, training, and cross-validating (or backtesting, if you prefer) simple and composite models/pipelines.</p> <p>We will use the dataset from an Energy residual load forcasting challenge hosted on Kaggle.</p> <p>By the end you will know how to: - Create a simple and ensemble model (composite model) - Train multiple models / pipelines over time - Analyze the model's simulated past performance</p> <p>Let's start by installing: - <code>fold</code> - <code>fold-wrappers</code>: optional, this will be required later for third party models. Wraps eg. <code>XGBoost</code> or <code>StatsForecast</code> models to be used with <code>fold</code>. - <code>krisi</code>, optional. Dream Faster's Time-Series evaluation library to quickly get results.</p>"},{"location":"walkthroughs/core_walkthrough/#installing-libraries","title":"Installing libraries","text":"<pre><code>%%capture\npip install --quiet fold-core fold-wrappers fold-models krisi matplotlib seaborn xgboost plotly prophet statsforecast statsmodels ray kaleido\n</code></pre>"},{"location":"walkthroughs/core_walkthrough/#data-loading-and-exploration","title":"Data Loading and Exploration","text":"<p>Let's load in the data and do minimal exploration of the structure of the data. </p> <p><code>fold</code> has a useful utility function that loads example data from our <code>datasets</code> GitHub repo. </p> <ul> <li>We are forecasting <code>residual_load</code>\u2021. </li> <li>We will shorten the dataset to <code>4000</code> rows so we have a speedier demonstration.</li> </ul> <p>\u2021 The difference between the <code>load</code> in the network and the <code>P</code> that the industrial complex is producing.</p> <pre><code>from fold.utils.dataset import get_preprocessed_dataset\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom krisi import score, compare\nfrom krisi.report import plot_y_predictions\nimport plotly.io as pio\npio.renderers.default = \"png\"\n\nX, y = get_preprocessed_dataset(\n    \"energy/industrial_pv_load\",\n    target_col=\"residual_load\", \n    resample=\"H\",\n    deduplication_strategy=\"first\",\n    shorten=4000,\n)\nno_of_observation_per_day = 24\nno_of_observation_per_week = no_of_observation_per_day * 7\n\ny.plot(figsize = (20,5), grid=True);\n</code></pre> <p></p> <p>The data format may be very familiar - it looks like the standard scikit-learn data.</p> <p><code>X</code> represents exogenous variables in <code>fold</code>, where a single row corresponds to a single target value. That means we currently only support univariate time-series (with exogenous variables), but soon we're extending that.</p> <p>It's important that the data should be sorted and its integrity (no missing values, no duplicate indicies) should be checked before passing data to <code>fold</code>.</p> <pre><code>X.head()\n</code></pre> P Gb(i) Gd(i) H_sun T2m WS10m load residual_load datetime 2018-01-01 00:00:00 0.0 0.0 0.0 0.0 8.44 5.54 120.0 120.0 2018-01-01 01:00:00 0.0 0.0 0.0 0.0 7.56 5.43 115.5 115.5 2018-01-01 02:00:00 0.0 0.0 0.0 0.0 7.04 5.33 120.5 120.5 2018-01-01 03:00:00 0.0 0.0 0.0 0.0 6.48 5.67 123.5 123.5 2018-01-01 04:00:00 0.0 0.0 0.0 0.0 5.95 5.79 136.5 136.5 <p>(We'll ignore the exogenous variables until a bit later)</p> <pre><code>y.head()\n</code></pre> <pre><code>datetime\n2018-01-01 00:00:00    115.5\n2018-01-01 01:00:00    120.5\n2018-01-01 02:00:00    123.5\n2018-01-01 03:00:00    136.5\n2018-01-01 04:00:00    138.0\nFreq: H, Name: residual_load, dtype: float64\n</code></pre> <p>You can see that <code>y</code> (our target) contains the next value of <code>X</code>'s \"residual_load\" column. </p>"},{"location":"walkthroughs/core_walkthrough/#time-series-cross-validation-with-a-univariate-forecaster","title":"Time Series Cross Validation with a univariate forecaster","text":""},{"location":"walkthroughs/core_walkthrough/#1-model-building","title":"1. Model Building","text":"<p><code>fold</code> has three core type of building blocks which you can build arbitrary sophisticated pipelines from: - Transformations (classes that change, augment the data. eg: <code>AddHolidayFeatures</code> adds a column feature of holidays/weekends to your exogenous variables) - Models (eg.: Sklearn, Baseline Models, third-party adapters from <code>fold-wrappers</code>, like Statsmodels) - Composites (eg.: <code>Ensemble</code> - takes the mean of the output of arbitrary number of 'parallel' models or pipelines)</p> <p>Let's use Facebook's popular <code>Prophet</code> library, and create in instance.</p> <p>If <code>fold-wrappers</code> is installed, <code>fold</code> can take this instance without any additional wrapper class.</p> <pre><code>from prophet import Prophet\nprophet = Prophet()\n</code></pre>"},{"location":"walkthroughs/core_walkthrough/#2-creating-a-splitter","title":"2. Creating a Splitter","text":"<p>A splitter allows us to do Time Series Cross-Validation with various strategies.</p> <p><code>fold</code> supports three types of <code>Splitters</code>: </p> <pre><code>from fold.splitters import ExpandingWindowSplitter\n\nsplitter = ExpandingWindowSplitter(\n    initial_train_window=no_of_observation_per_week * 6,\n    step=no_of_observation_per_week\n)\n</code></pre> <p>Here, <code>initial_train_window</code> defines the first window size, <code>step</code> is the size of the window between folds.</p> <p>We're gonna be using the first 6 weeks as our initial window, and re-train (or update, in another training mode) it every week after. We'll have 18 models, each predicting the next week's target variable.</p> <p>You can also use percentages to define both, for example, <code>0.1</code> would be equivalent to <code>10%</code> of the availabel data.</p>"},{"location":"walkthroughs/core_walkthrough/#3-training-a-univariate-model","title":"3. Training a (univariate) Model","text":"<p>We could use ray to parallelize the training of multiple folds, halving the time it takes for every CPU core we have available (or deploying it to a cluster, if needed).</p> <p>We pass in <code>None</code> as <code>X</code>, to indicate that we want to train a univariate model, without any exogenous variables.</p> <pre><code>from fold import train_evaluate, BackendType\nimport ray\nray.init(ignore_reinit_error=True)\n\nscorecard, predictions, trained_pipeline = train_evaluate(prophet, None, y, splitter, backend=BackendType.ray, krisi_args={\"model_name\":\"prophet\"})\n</code></pre>"},{"location":"walkthroughs/core_walkthrough/#4-evaluating-the-results","title":"4. Evaluating the results","text":"<pre><code>scorecard.print('minimal')\n</code></pre> <pre>                                               prophet\n                     Mean Absolute Error  9.507563e+01\n          Mean Absolute Percentage Error  7.955506e+13\nSymmetric Mean Absolute Percentage Error  5.092002e-01\n                      Mean Squared Error  1.477914e+04\n                 Root Mean Squared Error  1.215695e+02\n                               R-squared  4.268419e-01\n                   Mean of the Residuals  6.361641e+00\n     Standard Deviation of the Residuals  1.214232e+02\n</pre> <pre><code>plot_y_predictions(y[predictions.index], predictions, mode=\"overlap\", y_name=\"residual_load\")\n</code></pre> <p>Finally, let's save the scorecard into a list, so we can compare the results later.</p> <pre><code>results = [(scorecard, predictions)]\n</code></pre>"},{"location":"walkthroughs/core_walkthrough/#using-an-ensemble-composite-model","title":"Using an Ensemble (Composite) model","text":"<p>Here we will build an <code>Ensemble</code> model that leverages the output of multiple models. </p> <p></p>"},{"location":"walkthroughs/core_walkthrough/#1-model-building-with-fold-wrappers","title":"1. Model Building with <code>fold-wrappers</code>","text":"<p>We are going to define three different pipelines, each leveraging a different model and different features.</p> <p>We can leverage the most popular modelling libraries, like StatsForecast, Sktime, XGBoost, etc. (the list can be found here).</p> <p>Let's train a MSTL model that's implemented in StatsForecast, that can capture multiple seasonalities, with the <code>WrapStatsForecast</code> class from <code>fold-wrappers</code>. This is not strictly necessary, though, as the automatic wrapping also works for StatsForecast instaces as well.</p> <pre><code>from statsforecast.models import MSTL\nfrom fold.models.wrappers import WrapStatsForecast, WrapStatsModels\n\nmstl = WrapStatsForecast.from_model(MSTL([24, 168]))\n</code></pre>"},{"location":"walkthroughs/core_walkthrough/#2-ensembling-with-fold","title":"2. Ensembling with <code>fold</code>","text":"<p>Finally, let's <code>ensemble</code> the two pipelines.</p> <pre><code>from fold.composites import Ensemble\n\nunivariate_ensemble = Ensemble([prophet, mstl])\n</code></pre>"},{"location":"walkthroughs/core_walkthrough/#3-training-all-pipelines-seperately-and-within-an-ensemble","title":"3. Training all pipelines seperately and within an <code>ensemble</code>","text":"<p>We'll use the same <code>ExpandingWindowSplitter</code> we have defined above, to make performance comparable.</p> <pre><code>from fold import train_evaluate\n\nfor name, pipeline in [\n    (\"mstl\", mstl),\n    (\"univariate_ensemble\",univariate_ensemble)\n]:\n    scorecard, predictions, pipeline_trained = train_evaluate(pipeline, None, y, splitter, krisi_args={\"model_name\":name})\n    results.append((scorecard, predictions))\n</code></pre> <pre><code>compare([scorecard for scorecard, predictions in results], ['rmse', 'mse'])\n</code></pre> rmse mse prophet 121.569502 14779.143772 mstl 118.703683 14090.564243 univariate_ensemble 105.962271 11228.002822 <p>We see that our Ensemble model has beaten all individual models' performance - which is very usual in the time series context.</p>"},{"location":"walkthroughs/core_walkthrough/#using-a-single-step-ahead-forecaster-a-baseline","title":"Using a single-step ahead forecaster (a baseline)","text":"<p>So far we've used models that were costly to update (or re-train) every day, therefore we were limited to training once for every week, then predicting the next week's target.</p> <p>What if we could use a lightweight, \"online\" model, that can be updated on every timestamp?</p> <p>And.. what if we just repeat the last value?</p> <p>That'd be the <code>Naive</code> model you can load from <code>fold.models</code>.</p> <pre><code>from fold import train_evaluate\nfrom fold.models import Naive\n\nscorecard, predictions, trained_pipeline = train_evaluate(Naive(), None, y, splitter, krisi_args={\"model_name\":\"naive\"})\nresults.append((scorecard, predictions))\nscorecard.print(\"minimal\")\n</code></pre> <pre><code>  0%|          | 0/18 [00:00&lt;?, ?it/s]\n\n\n\n  0%|          | 0/18 [00:00&lt;?, ?it/s]\n</code></pre> <pre>                                                 naive\n                     Mean Absolute Error  3.911054e+01\n          Mean Absolute Percentage Error  2.122351e+14\nSymmetric Mean Absolute Percentage Error  2.038015e-01\n                      Mean Squared Error  4.012944e+03\n                 Root Mean Squared Error  6.334780e+01\n                               R-squared  8.443718e-01\n                   Mean of the Residuals -4.387701e-02\n     Standard Deviation of the Residuals  6.335837e+01\n</pre> <p>We call this Adaptive Backtesting.</p> <p>It looks like having access to last value really makes a difference: the baseline model beats all long-term forecasting models by a large margin.</p> <p>It's extremely important to define our forecasting task well: 1. We need to think about what time horizon can and should forecast 2. And how frequently can we update our models.</p> <p>Long-horizon (in this case, a week ahead) forecasts can be very unreliable, on the other hand, frequent, short-term forecasts are where Machine Learning shines (as we'll see in the next section).</p>"},{"location":"walkthroughs/core_walkthrough/#using-exogenous-variables-with-tabular-models","title":"Using exogenous variables with Tabular Models","text":"<p>So far we have been training univariate models, and ignored all the additional, exogenous variables that come with our data.</p> <p>Let's try whether using this data boost our model's performance!</p>"},{"location":"walkthroughs/core_walkthrough/#building-models-separately","title":"Building Models separately","text":"<p>We'll be using scikit-learn's <code>HistGradientBoostingRegressor</code>, their competing implementation of Gradient Boosted Trees. You don't need to wrap <code>scikit-learn</code> models or transformations when using it in <code>fold</code>, just pass it in directly to any pipeline.</p> <pre><code>from sklearn.ensemble import HistGradientBoostingRegressor\n\ntree_model = HistGradientBoostingRegressor(max_depth=10)\n</code></pre> <p>Let's add both holiday and date-time features to our previous ensemble pipeline.</p> <p>The data was gathered in the Region of Hessen, Germany -- so we pass in <code>DE</code> (we can pass in multiple regions). This transformation adds another column for holidays to our <code>exogenous</code> (<code>X</code>) features.</p> <p>We're also adding the current hour, and day of week as integers to our exogenous features. This is one of the ways for our tabular model to capture seasonality.</p> <pre><code>from fold.transformations import AddHolidayFeatures, AddDateTimeFeatures\n\ndatetime = AddDateTimeFeatures(['hour', 'day_of_week', 'day_of_year'])\nholidays = AddHolidayFeatures(['DE'])\n</code></pre> <p>Let's add a couple of lagged, exogenous values for our model. <code>AddLagsX</code> receives a tuple of column name and integer or list of lags, for each of which it will create a column in <code>X</code>.</p> <p>We can easily create transformations of existing features on a rolling window basis with <code>AddWindowFeatures</code> as well, in this case, the last day's average value for all of our exogenous features.</p> <p>We can \"tie in\" two separate pipelines with <code>Concat</code>, which concatenates all columns from all sources.</p> <pre><code>from fold.transformations import AddWindowFeatures, AddLagsX\nfrom fold.composites import Concat\n\ntree = [\n    Concat([\n        AddLagsX((\"all\",range(1,3))),\n        AddWindowFeatures([(\"all\", 24, \"mean\")]),\n    ]),\n    datetime,\n    holidays,\n    tree_model\n]\n</code></pre> <p>Let's see how this performs!</p> <p>We can also use fold's <code>train</code>, <code>backtest</code> to decouple these functionalities.</p> <pre><code>from fold import train, backtest\n\ntrained_pipeline = train(tree, X, y, splitter)\npredictions = backtest(trained_pipeline, X, y, splitter)\nscorecard = score(y[predictions.index], predictions.squeeze(), model_name=\"tabular_tree\")\n\nresults.append((scorecard, predictions))\nscorecard.print(\"minimal\")\n</code></pre> <pre><code>  0%|          | 0/18 [00:00&lt;?, ?it/s]\n\n\n\n  0%|          | 0/18 [00:00&lt;?, ?it/s]\n</code></pre> <pre>                                          tabular_tree\n                     Mean Absolute Error  2.965292e+01\n          Mean Absolute Percentage Error  2.123209e+14\nSymmetric Mean Absolute Percentage Error  1.591514e-01\n                      Mean Squared Error  2.637592e+03\n                 Root Mean Squared Error  5.135749e+01\n                               R-squared  8.977101e-01\n                   Mean of the Residuals -1.747140e+00\n     Standard Deviation of the Residuals  5.133635e+01\n</pre>"},{"location":"walkthroughs/core_walkthrough/#creating-an-ensemble-of-tabular-models","title":"Creating an Ensemble of Tabular models","text":"<p>First let's creat two more models: * an Sklearn LinearRegressor * and an XGBoostRegressor instance</p> <p>We are also going to use the HistGradientBoostingRegressor pipeline that we defined prior.</p> <pre><code>from sklearn.linear_model import LinearRegression\n\nlregression = [\n    AddLagsX(('all',range(1,3))),\n    datetime,\n    LinearRegression()\n]\n</code></pre> <pre><code>from xgboost import XGBRegressor\nfrom fold.models.wrappers.gbd import WrapXGB\n\nxgboost = [\n    AddLagsX(('all',range(1,3))),\n    datetime,\n    WrapXGB.from_model(XGBRegressor())\n]\n</code></pre> <pre><code>tabular_ensemble = Ensemble([lregression, xgboost, tree])\n</code></pre> <pre><code>scorecard, predictions, pipeline_trained = train_evaluate(tabular_ensemble, X, y, splitter, krisi_args={\"model_name\":\"tabular_ensemble\"})\nresults.append((scorecard, predictions))\n</code></pre> <pre><code>  0%|          | 0/18 [00:00&lt;?, ?it/s]\n\n\n\n  0%|          | 0/18 [00:00&lt;?, ?it/s]\n</code></pre>"},{"location":"walkthroughs/core_walkthrough/#comparing-vizualising-the-results","title":"Comparing &amp; Vizualising the results","text":"<pre><code>compare([scorecard for scorecard, _ in results], sort_by=\"rmse\")\n</code></pre> rmse mae mape smape mse r_two residuals_mean residuals_std prophet 121.569502 95.075627 7.955506e+13 0.509200 14779.143772 0.426842 6.361641 121.423231 mstl 118.703683 68.464305 1.846641e+14 0.279174 14090.564243 0.453546 13.258315 117.980649 univariate_ensemble 105.962271 73.283533 1.321096e+14 0.356740 11228.002822 0.564561 9.809978 105.524826 naive 63.347800 39.110541 2.122351e+14 0.203802 4012.943794 0.844372 -0.043877 63.358374 tabular_tree 51.357493 29.652915 2.123209e+14 0.159151 2637.592134 0.897710 -1.747140 51.336346 tabular_ensemble 48.228591 28.165175 2.113763e+14 0.153255 2325.997006 0.909794 -2.690336 48.161544 <p>In this simplistic, unfair comparison, it looks like the tabular models (and the Naive baseline) that have access to the previous value (and the exogenous variables) outperform the univariate models that are only re-trained every week. </p> <p>We can't really draw general conclusions from this work, though. </p> <p>Unlike NLP and Computer vision, Time Series data is very heterogeneous, and a Machine Learning approach that works well for one series may be an inferior choice for your specific usecase.</p> <p>But now we have an easy way to compare the different pipelines, with unprecedented speed, by using a unified interface, with fold. </p> <pre><code>all_predictions =[predictions.squeeze().rename(scorecard.metadata.model_name) for scorecard, predictions in results]\n\nplot_y_predictions(y[predictions.index], all_predictions, y_name=\"residual_load\", mode='seperate')\n</code></pre> <p></p> <p>Want to know more? Visit fold's Examples page, and access all the necessary snippets you need for you to build a Time Series ML pipeline!</p>"}]}